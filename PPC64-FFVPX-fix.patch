From 8bceafeb6015833b996d46314aa7045732234fc9 Mon Sep 17 00:00:00 2001
From: Sergey Larin <cerg2010cerg2010@mail.ru>
Date: Wed, 9 Jul 2025 01:55:38 +0000
Subject: [PATCH] Issue #2777 - Fix ffvpx build on PPC64

---
 media/ffvpx/config.h                          |   2 +
 media/ffvpx/config_unix_ppc.h                 | 770 ++++++++++++++++++
 media/ffvpx/libavcodec/moz.build              |   2 +
 media/ffvpx/libavcodec/ppc/hpeldsp_altivec.c  | 386 +++++++++
 media/ffvpx/libavcodec/ppc/hpeldsp_altivec.h  |  34 +
 media/ffvpx/libavcodec/ppc/mathops.h          |  79 ++
 media/ffvpx/libavcodec/ppc/moz.build          |  14 +
 media/ffvpx/libavcodec/ppc/videodsp.c         |  36 +
 media/ffvpx/libavcodec/ppc/vp8dsp_altivec.c   | 362 ++++++++
 media/ffvpx/libavutil/moz.build               |   2 +
 media/ffvpx/libavutil/ppc/cpu.c               | 165 ++++
 media/ffvpx/libavutil/ppc/cpu.h               |  29 +
 media/ffvpx/libavutil/ppc/float_dsp_altivec.c | 124 +++
 media/ffvpx/libavutil/ppc/float_dsp_altivec.h |  38 +
 media/ffvpx/libavutil/ppc/float_dsp_init.c    |  52 ++
 media/ffvpx/libavutil/ppc/float_dsp_vsx.c     | 119 +++
 media/ffvpx/libavutil/ppc/float_dsp_vsx.h     |  38 +
 media/ffvpx/libavutil/ppc/intreadwrite.h      | 110 +++
 media/ffvpx/libavutil/ppc/moz.build           |  15 +
 media/ffvpx/libavutil/ppc/timer.h             |  48 ++
 media/ffvpx/libavutil/ppc/util_altivec.h      | 195 +++++
 21 files changed, 2620 insertions(+)
 create mode 100644 media/ffvpx/config_unix_ppc.h
 create mode 100644 media/ffvpx/libavcodec/ppc/hpeldsp_altivec.c
 create mode 100644 media/ffvpx/libavcodec/ppc/hpeldsp_altivec.h
 create mode 100644 media/ffvpx/libavcodec/ppc/mathops.h
 create mode 100644 media/ffvpx/libavcodec/ppc/moz.build
 create mode 100644 media/ffvpx/libavcodec/ppc/videodsp.c
 create mode 100644 media/ffvpx/libavcodec/ppc/vp8dsp_altivec.c
 create mode 100644 media/ffvpx/libavutil/ppc/cpu.c
 create mode 100644 media/ffvpx/libavutil/ppc/cpu.h
 create mode 100644 media/ffvpx/libavutil/ppc/float_dsp_altivec.c
 create mode 100644 media/ffvpx/libavutil/ppc/float_dsp_altivec.h
 create mode 100644 media/ffvpx/libavutil/ppc/float_dsp_init.c
 create mode 100644 media/ffvpx/libavutil/ppc/float_dsp_vsx.c
 create mode 100644 media/ffvpx/libavutil/ppc/float_dsp_vsx.h
 create mode 100644 media/ffvpx/libavutil/ppc/intreadwrite.h
 create mode 100644 media/ffvpx/libavutil/ppc/moz.build
 create mode 100644 media/ffvpx/libavutil/ppc/timer.h
 create mode 100644 media/ffvpx/libavutil/ppc/util_altivec.h

diff --git a/media/ffvpx/config.h b/media/ffvpx/config.h
index 9eb2467a1b..43d3137a95 100644
--- a/media/ffvpx/config.h
+++ b/media/ffvpx/config.h
@@ -39,6 +39,8 @@
 #elif defined(XP_UNIX)
 #if defined(__aarch64__)
 #include "config_unix_aarch64.h"
+#elif defined(__powerpc__)
+#include "config_unix_ppc.h"
 #else
 #if defined(HAVE_64BIT_BUILD)
 #include "config_unix64.h"
diff --git a/media/ffvpx/config_unix_ppc.h b/media/ffvpx/config_unix_ppc.h
new file mode 100644
index 0000000000..f06c70952b
--- /dev/null
+++ b/media/ffvpx/config_unix_ppc.h
@@ -0,0 +1,770 @@
+/* Automatically generated by configure - do not modify! */
+#ifndef FFMPEG_CONFIG_H
+#define FFMPEG_CONFIG_H
+#define FFMPEG_CONFIGURATION "--disable-all --enable-avcodec --enable-decoder='vp8,vp9,flac' --enable-parser='vp8,vp9' --disable-static --enable-shared --disable-autodetect --disable-iconv --disable-linux-perf"
+#define FFMPEG_LICENSE "LGPL version 2.1 or later"
+#define CONFIG_THIS_YEAR 2024
+#define FFMPEG_DATADIR "/usr/local/share/ffmpeg"
+#define AVCONV_DATADIR "/usr/local/share/ffmpeg"
+#define CC_IDENT "gcc 13.3.0 (Adelie 13.3.0)"
+#define OS_NAME linux
+#define av_restrict restrict
+#define EXTERN_PREFIX ""
+#define EXTERN_ASM 
+#define BUILDSUF ""
+#define SLIBSUF ".so"
+#define HAVE_MMX2 HAVE_MMXEXT
+#define SWS_MAX_FILTER_SIZE 256
+#define ARCH_AARCH64 0
+#define ARCH_ALPHA 0
+#define ARCH_ARM 0
+#define ARCH_AVR32 0
+#define ARCH_AVR32_AP 0
+#define ARCH_AVR32_UC 0
+#define ARCH_BFIN 0
+#define ARCH_IA64 0
+#define ARCH_LOONGARCH 0
+#define ARCH_LOONGARCH32 0
+#define ARCH_LOONGARCH64 0
+#define ARCH_M68K 0
+#define ARCH_MIPS 0
+#define ARCH_MIPS64 0
+#define ARCH_PARISC 0
+#define ARCH_PPC 1
+#ifdef __powerpc64__
+#define ARCH_PPC64 1
+#else
+#define ARCH_PPC64 0
+#endif
+#define ARCH_RISCV 0
+#define ARCH_S390 0
+#define ARCH_SH4 0
+#define ARCH_SPARC 0
+#define ARCH_SPARC64 0
+#define ARCH_TILEGX 0
+#define ARCH_TILEPRO 0
+#define ARCH_X86 0
+#define ARCH_X86_32 0
+#define ARCH_X86_64 0
+#define HAVE_ARMV5TE 0
+#define HAVE_ARMV6 0
+#define HAVE_ARMV6T2 0
+#define HAVE_ARMV8 0
+#define HAVE_DOTPROD 0
+#define HAVE_I8MM 0
+#define HAVE_NEON 0
+#define HAVE_VFP 0
+#define HAVE_VFPV3 0
+#define HAVE_SETEND 0
+#ifdef __ALTIVEC__
+#define HAVE_ALTIVEC 1
+#else
+#define HAVE_ALTIVEC 0
+#endif
+#define HAVE_DCBZL 1
+#define HAVE_LDBRX 0
+#define HAVE_POWER8 0
+#define HAVE_PPC4XX 0
+#define HAVE_VSX 0
+#define HAVE_RVV 0
+#define HAVE_AESNI 0
+#define HAVE_AMD3DNOW 0
+#define HAVE_AMD3DNOWEXT 0
+#define HAVE_AVX 0
+#define HAVE_AVX2 0
+#define HAVE_AVX512 0
+#define HAVE_AVX512ICL 0
+#define HAVE_FMA3 0
+#define HAVE_FMA4 0
+#define HAVE_MMX 0
+#define HAVE_MMXEXT 0
+#define HAVE_SSE 0
+#define HAVE_SSE2 0
+#define HAVE_SSE3 0
+#define HAVE_SSE4 0
+#define HAVE_SSE42 0
+#define HAVE_SSSE3 0
+#define HAVE_XOP 0
+#define HAVE_CPUNOP 0
+#define HAVE_I686 0
+#define HAVE_MIPSFPU 0
+#define HAVE_MIPS32R2 0
+#define HAVE_MIPS32R5 0
+#define HAVE_MIPS64R2 0
+#define HAVE_MIPS32R6 0
+#define HAVE_MIPS64R6 0
+#define HAVE_MIPSDSP 0
+#define HAVE_MIPSDSPR2 0
+#define HAVE_MSA 0
+#define HAVE_LOONGSON2 0
+#define HAVE_LOONGSON3 0
+#define HAVE_MMI 0
+#define HAVE_LSX 0
+#define HAVE_LASX 0
+#define HAVE_ARMV5TE_EXTERNAL 0
+#define HAVE_ARMV6_EXTERNAL 0
+#define HAVE_ARMV6T2_EXTERNAL 0
+#define HAVE_ARMV8_EXTERNAL 0
+#define HAVE_DOTPROD_EXTERNAL 0
+#define HAVE_I8MM_EXTERNAL 0
+#define HAVE_NEON_EXTERNAL 0
+#define HAVE_VFP_EXTERNAL 0
+#define HAVE_VFPV3_EXTERNAL 0
+#define HAVE_SETEND_EXTERNAL 0
+#define HAVE_ALTIVEC_EXTERNAL 0
+#define HAVE_DCBZL_EXTERNAL 0
+#define HAVE_LDBRX_EXTERNAL 0
+#define HAVE_POWER8_EXTERNAL 0
+#define HAVE_PPC4XX_EXTERNAL 0
+#define HAVE_VSX_EXTERNAL 0
+#define HAVE_RVV_EXTERNAL 0
+#define HAVE_AESNI_EXTERNAL 0
+#define HAVE_AMD3DNOW_EXTERNAL 0
+#define HAVE_AMD3DNOWEXT_EXTERNAL 0
+#define HAVE_AVX_EXTERNAL 0
+#define HAVE_AVX2_EXTERNAL 0
+#define HAVE_AVX512_EXTERNAL 0
+#define HAVE_AVX512ICL_EXTERNAL 0
+#define HAVE_FMA3_EXTERNAL 0
+#define HAVE_FMA4_EXTERNAL 0
+#define HAVE_MMX_EXTERNAL 0
+#define HAVE_MMXEXT_EXTERNAL 0
+#define HAVE_SSE_EXTERNAL 0
+#define HAVE_SSE2_EXTERNAL 0
+#define HAVE_SSE3_EXTERNAL 0
+#define HAVE_SSE4_EXTERNAL 0
+#define HAVE_SSE42_EXTERNAL 0
+#define HAVE_SSSE3_EXTERNAL 0
+#define HAVE_XOP_EXTERNAL 0
+#define HAVE_CPUNOP_EXTERNAL 0
+#define HAVE_I686_EXTERNAL 0
+#define HAVE_MIPSFPU_EXTERNAL 0
+#define HAVE_MIPS32R2_EXTERNAL 0
+#define HAVE_MIPS32R5_EXTERNAL 0
+#define HAVE_MIPS64R2_EXTERNAL 0
+#define HAVE_MIPS32R6_EXTERNAL 0
+#define HAVE_MIPS64R6_EXTERNAL 0
+#define HAVE_MIPSDSP_EXTERNAL 0
+#define HAVE_MIPSDSPR2_EXTERNAL 0
+#define HAVE_MSA_EXTERNAL 0
+#define HAVE_LOONGSON2_EXTERNAL 0
+#define HAVE_LOONGSON3_EXTERNAL 0
+#define HAVE_MMI_EXTERNAL 0
+#define HAVE_LSX_EXTERNAL 0
+#define HAVE_LASX_EXTERNAL 0
+#define HAVE_ARMV5TE_INLINE 0
+#define HAVE_ARMV6_INLINE 0
+#define HAVE_ARMV6T2_INLINE 0
+#define HAVE_ARMV8_INLINE 0
+#define HAVE_DOTPROD_INLINE 0
+#define HAVE_I8MM_INLINE 0
+#define HAVE_NEON_INLINE 0
+#define HAVE_VFP_INLINE 0
+#define HAVE_VFPV3_INLINE 0
+#define HAVE_SETEND_INLINE 0
+#define HAVE_ALTIVEC_INLINE 0
+#define HAVE_DCBZL_INLINE 0
+#define HAVE_LDBRX_INLINE 0
+#define HAVE_POWER8_INLINE 0
+#define HAVE_PPC4XX_INLINE 0
+#define HAVE_VSX_INLINE 0
+#define HAVE_RVV_INLINE 0
+#define HAVE_AESNI_INLINE 0
+#define HAVE_AMD3DNOW_INLINE 0
+#define HAVE_AMD3DNOWEXT_INLINE 0
+#define HAVE_AVX_INLINE 0
+#define HAVE_AVX2_INLINE 0
+#define HAVE_AVX512_INLINE 0
+#define HAVE_AVX512ICL_INLINE 0
+#define HAVE_FMA3_INLINE 0
+#define HAVE_FMA4_INLINE 0
+#define HAVE_MMX_INLINE 0
+#define HAVE_MMXEXT_INLINE 0
+#define HAVE_SSE_INLINE 0
+#define HAVE_SSE2_INLINE 0
+#define HAVE_SSE3_INLINE 0
+#define HAVE_SSE4_INLINE 0
+#define HAVE_SSE42_INLINE 0
+#define HAVE_SSSE3_INLINE 0
+#define HAVE_XOP_INLINE 0
+#define HAVE_CPUNOP_INLINE 0
+#define HAVE_I686_INLINE 0
+#define HAVE_MIPSFPU_INLINE 0
+#define HAVE_MIPS32R2_INLINE 0
+#define HAVE_MIPS32R5_INLINE 0
+#define HAVE_MIPS64R2_INLINE 0
+#define HAVE_MIPS32R6_INLINE 0
+#define HAVE_MIPS64R6_INLINE 0
+#define HAVE_MIPSDSP_INLINE 0
+#define HAVE_MIPSDSPR2_INLINE 0
+#define HAVE_MSA_INLINE 0
+#define HAVE_LOONGSON2_INLINE 0
+#define HAVE_LOONGSON3_INLINE 0
+#define HAVE_MMI_INLINE 0
+#define HAVE_LSX_INLINE 0
+#define HAVE_LASX_INLINE 0
+#define HAVE_ALIGNED_STACK 1
+#define HAVE_FAST_64BIT 1
+#define HAVE_FAST_CLZ 1
+#define HAVE_FAST_CMOV 0
+#define HAVE_FAST_FLOAT16 0
+#define HAVE_LOCAL_ALIGNED 1
+#define HAVE_SIMD_ALIGN_16 1
+#define HAVE_SIMD_ALIGN_32 0
+#define HAVE_SIMD_ALIGN_64 0
+#define HAVE_ATOMIC_CAS_PTR 0
+#define HAVE_MACHINE_RW_BARRIER 0
+#define HAVE_MEMORYBARRIER 0
+#define HAVE_MM_EMPTY 0
+#define HAVE_RDTSC 0
+#define HAVE_SEM_TIMEDWAIT 1
+#define HAVE_SYNC_VAL_COMPARE_AND_SWAP 1
+#define HAVE_INLINE_ASM 1
+#define HAVE_SYMVER 1
+#define HAVE_X86ASM 0
+#define HAVE_BIGENDIAN 1
+#define HAVE_FAST_UNALIGNED 1
+#define HAVE_ARPA_INET_H 1
+#define HAVE_ASM_TYPES_H 1
+#define HAVE_CDIO_PARANOIA_H 0
+#define HAVE_CDIO_PARANOIA_PARANOIA_H 0
+#define HAVE_CUDA_H 0
+#define HAVE_DISPATCH_DISPATCH_H 0
+#define HAVE_DEV_BKTR_IOCTL_BT848_H 0
+#define HAVE_DEV_BKTR_IOCTL_METEOR_H 0
+#define HAVE_DEV_IC_BT8XX_H 0
+#define HAVE_DEV_VIDEO_BKTR_IOCTL_BT848_H 0
+#define HAVE_DEV_VIDEO_METEOR_IOCTL_METEOR_H 0
+#define HAVE_DIRECT_H 0
+#define HAVE_DIRENT_H 1
+#define HAVE_DXGIDEBUG_H 0
+#define HAVE_DXVA_H 0
+#define HAVE_ES2_GL_H 0
+#define HAVE_GSM_H 0
+#define HAVE_IO_H 0
+#define HAVE_LINUX_DMA_BUF_H 0
+#define HAVE_LINUX_PERF_EVENT_H 1
+#define HAVE_MACHINE_IOCTL_BT848_H 0
+#define HAVE_MACHINE_IOCTL_METEOR_H 0
+#define HAVE_MALLOC_H 1
+#define HAVE_OPENCV2_CORE_CORE_C_H 0
+#define HAVE_OPENGL_GL3_H 0
+#define HAVE_POLL_H 1
+#define HAVE_PTHREAD_NP_H 0
+#define HAVE_SYS_PARAM_H 1
+#define HAVE_SYS_RESOURCE_H 1
+#define HAVE_SYS_SELECT_H 1
+#define HAVE_SYS_SOUNDCARD_H 1
+#define HAVE_SYS_TIME_H 1
+#define HAVE_SYS_UN_H 1
+#define HAVE_SYS_VIDEOIO_H 0
+#define HAVE_TERMIOS_H 1
+#define HAVE_UDPLITE_H 0
+#define HAVE_UNISTD_H 1
+#define HAVE_VALGRIND_VALGRIND_H 0
+#define HAVE_WINDOWS_H 0
+#define HAVE_WINSOCK2_H 0
+#define HAVE_INTRINSICS_NEON 0
+#define HAVE_ATANF 1
+#define HAVE_ATAN2F 1
+#define HAVE_CBRT 1
+#define HAVE_CBRTF 1
+#define HAVE_COPYSIGN 1
+#define HAVE_COSF 1
+#define HAVE_ERF 1
+#define HAVE_EXP2 1
+#define HAVE_EXP2F 1
+#define HAVE_EXPF 1
+#define HAVE_HYPOT 1
+#define HAVE_ISFINITE 1
+#define HAVE_ISINF 1
+#define HAVE_ISNAN 1
+#define HAVE_LDEXPF 1
+#define HAVE_LLRINT 1
+#define HAVE_LLRINTF 1
+#define HAVE_LOG2 1
+#define HAVE_LOG2F 1
+#define HAVE_LOG10F 1
+#define HAVE_LRINT 1
+#define HAVE_LRINTF 1
+#define HAVE_POWF 1
+#define HAVE_RINT 1
+#define HAVE_ROUND 1
+#define HAVE_ROUNDF 1
+#define HAVE_SINF 1
+#define HAVE_TRUNC 1
+#define HAVE_TRUNCF 1
+#define HAVE_DOS_PATHS 0
+#define HAVE_LIBC_MSVCRT 0
+#define HAVE_MMAL_PARAMETER_VIDEO_MAX_NUM_CALLBACKS 0
+#define HAVE_SECTION_DATA_REL_RO 1
+#define HAVE_THREADS 1
+#define HAVE_UWP 0
+#define HAVE_WINRT 0
+#define HAVE_ACCESS 1
+#define HAVE_ALIGNED_MALLOC 0
+#define HAVE_ARC4RANDOM_BUF 0
+#define HAVE_CLOCK_GETTIME 1
+#define HAVE_CLOSESOCKET 0
+#define HAVE_COMMANDLINETOARGVW 0
+#define HAVE_FCNTL 1
+#define HAVE_GETADDRINFO 1
+#define HAVE_GETAUXVAL 1
+#define HAVE_GETENV 1
+#define HAVE_GETHRTIME 0
+#define HAVE_GETOPT 1
+#define HAVE_GETMODULEHANDLE 0
+#define HAVE_GETPROCESSAFFINITYMASK 0
+#define HAVE_GETPROCESSMEMORYINFO 0
+#define HAVE_GETPROCESSTIMES 0
+#define HAVE_GETRUSAGE 1
+#define HAVE_GETSTDHANDLE 0
+#define HAVE_GETSYSTEMTIMEASFILETIME 0
+#define HAVE_GETTIMEOFDAY 1
+#define HAVE_GLOB 1
+#define HAVE_GLXGETPROCADDRESS 0
+#define HAVE_GMTIME_R 1
+#define HAVE_INET_ATON 1
+#define HAVE_ISATTY 1
+#define HAVE_KBHIT 0
+#define HAVE_LOCALTIME_R 1
+#define HAVE_LSTAT 1
+#define HAVE_LZO1X_999_COMPRESS 0
+#define HAVE_MACH_ABSOLUTE_TIME 0
+#define HAVE_MAPVIEWOFFILE 0
+#define HAVE_MEMALIGN 1
+#define HAVE_MKSTEMP 1
+#define HAVE_MMAP 1
+#define HAVE_MPROTECT 1
+#define HAVE_NANOSLEEP 1
+#define HAVE_PEEKNAMEDPIPE 0
+#define HAVE_POSIX_MEMALIGN 1
+#define HAVE_PRCTL 1
+#define HAVE_PTHREAD_CANCEL 1
+#define HAVE_PTHREAD_SET_NAME_NP 0
+#define HAVE_PTHREAD_SETNAME_NP 0
+#define HAVE_SCHED_GETAFFINITY 1
+#define HAVE_SECITEMIMPORT 0
+#define HAVE_SETCONSOLETEXTATTRIBUTE 0
+#define HAVE_SETCONSOLECTRLHANDLER 0
+#define HAVE_SETDLLDIRECTORY 0
+#define HAVE_SETMODE 0
+#define HAVE_SETRLIMIT 1
+#define HAVE_SLEEP 0
+#define HAVE_STRERROR_R 1
+#define HAVE_SYSCONF 1
+#define HAVE_SYSCTL 0
+#define HAVE_SYSCTLBYNAME 0
+#define HAVE_USLEEP 1
+#define HAVE_UTGETOSTYPEFROMSTRING 0
+#define HAVE_VIRTUALALLOC 0
+#define HAVE_WGLGETPROCADDRESS 0
+#define HAVE_BCRYPT 0
+#define HAVE_VAAPI_DRM 0
+#define HAVE_VAAPI_X11 0
+#define HAVE_VAAPI_WIN32 0
+#define HAVE_VDPAU_X11 0
+#define HAVE_PTHREADS 1
+#define HAVE_OS2THREADS 0
+#define HAVE_W32THREADS 0
+#define HAVE_AS_ARCH_DIRECTIVE 0
+#define HAVE_AS_ARCHEXT_DOTPROD_DIRECTIVE 0
+#define HAVE_AS_ARCHEXT_I8MM_DIRECTIVE 0
+#define HAVE_AS_DN_DIRECTIVE 0
+#define HAVE_AS_FPU_DIRECTIVE 0
+#define HAVE_AS_FUNC 1
+#define HAVE_AS_OBJECT_ARCH 0
+#define HAVE_ASM_MOD_Q 0
+#define HAVE_BLOCKS_EXTENSION 0
+#define HAVE_EBP_AVAILABLE 0
+#define HAVE_EBX_AVAILABLE 0
+#define HAVE_GNU_AS 0
+#define HAVE_GNU_WINDRES 0
+#define HAVE_IBM_ASM 1
+#define HAVE_INLINE_ASM_DIRECT_SYMBOL_REFS 0
+#define HAVE_INLINE_ASM_LABELS 1
+#define HAVE_INLINE_ASM_NONLOCAL_LABELS 1
+#define HAVE_PRAGMA_DEPRECATED 1
+#define HAVE_RSYNC_CONTIMEOUT 0
+#define HAVE_SYMVER_ASM_LABEL 0
+#define HAVE_SYMVER_GNU_ASM 1
+#define HAVE_VFP_ARGS 0
+#define HAVE_XFORM_ASM 1
+#define HAVE_XMM_CLOBBERS 0
+#define HAVE_DPI_AWARENESS_CONTEXT 0
+#define HAVE_IDXGIOUTPUT5 0
+#define HAVE_KCMVIDEOCODECTYPE_HEVC 0
+#define HAVE_KCMVIDEOCODECTYPE_HEVCWITHALPHA 0
+#define HAVE_KCMVIDEOCODECTYPE_VP9 0
+#define HAVE_KCVPIXELFORMATTYPE_420YPCBCR10BIPLANARVIDEORANGE 0
+#define HAVE_KCVPIXELFORMATTYPE_422YPCBCR8BIPLANARVIDEORANGE 0
+#define HAVE_KCVPIXELFORMATTYPE_422YPCBCR10BIPLANARVIDEORANGE 0
+#define HAVE_KCVPIXELFORMATTYPE_422YPCBCR16BIPLANARVIDEORANGE 0
+#define HAVE_KCVPIXELFORMATTYPE_444YPCBCR8BIPLANARVIDEORANGE 0
+#define HAVE_KCVPIXELFORMATTYPE_444YPCBCR10BIPLANARVIDEORANGE 0
+#define HAVE_KCVPIXELFORMATTYPE_444YPCBCR16BIPLANARVIDEORANGE 0
+#define HAVE_KCVIMAGEBUFFERTRANSFERFUNCTION_SMPTE_ST_2084_PQ 0
+#define HAVE_KCVIMAGEBUFFERTRANSFERFUNCTION_ITU_R_2100_HLG 0
+#define HAVE_KCVIMAGEBUFFERTRANSFERFUNCTION_LINEAR 0
+#define HAVE_KCVIMAGEBUFFERYCBCRMATRIX_ITU_R_2020 0
+#define HAVE_KCVIMAGEBUFFERCOLORPRIMARIES_ITU_R_2020 0
+#define HAVE_KCVIMAGEBUFFERTRANSFERFUNCTION_ITU_R_2020 0
+#define HAVE_KCVIMAGEBUFFERTRANSFERFUNCTION_SMPTE_ST_428_1 0
+#define HAVE_SOCKLEN_T 1
+#define HAVE_STRUCT_ADDRINFO 1
+#define HAVE_STRUCT_GROUP_SOURCE_REQ 1
+#define HAVE_STRUCT_IP_MREQ_SOURCE 1
+#define HAVE_STRUCT_IPV6_MREQ 1
+#define HAVE_STRUCT_MSGHDR_MSG_FLAGS 1
+#define HAVE_STRUCT_POLLFD 1
+#define HAVE_STRUCT_RUSAGE_RU_MAXRSS 1
+#define HAVE_STRUCT_SCTP_EVENT_SUBSCRIBE 0
+#define HAVE_STRUCT_SOCKADDR_IN6 1
+#define HAVE_STRUCT_SOCKADDR_SA_LEN 0
+#define HAVE_STRUCT_SOCKADDR_STORAGE 1
+#define HAVE_STRUCT_STAT_ST_MTIM_TV_NSEC 1
+#define HAVE_STRUCT_V4L2_FRMIVALENUM_DISCRETE 0
+#define HAVE_GZIP 1
+#define HAVE_LIBDRM_GETFB2 0
+#define HAVE_MAKEINFO 0
+#define HAVE_MAKEINFO_HTML 0
+#define HAVE_OPENCL_D3D11 0
+#define HAVE_OPENCL_DRM_ARM 0
+#define HAVE_OPENCL_DRM_BEIGNET 0
+#define HAVE_OPENCL_DXVA2 0
+#define HAVE_OPENCL_VAAPI_BEIGNET 0
+#define HAVE_OPENCL_VAAPI_INTEL_MEDIA 0
+#define HAVE_PERL 1
+#define HAVE_POD2MAN 1
+#define HAVE_TEXI2HTML 0
+#define HAVE_XMLLINT 1
+#define HAVE_ZLIB_GZIP 0
+#define HAVE_OPENVINO2 0
+#define CONFIG_DOC 0
+#define CONFIG_HTMLPAGES 0
+#define CONFIG_MANPAGES 1
+#define CONFIG_PODPAGES 1
+#define CONFIG_TXTPAGES 0
+#define CONFIG_AVIO_HTTP_SERVE_FILES_EXAMPLE 1
+#define CONFIG_AVIO_LIST_DIR_EXAMPLE 1
+#define CONFIG_AVIO_READ_CALLBACK_EXAMPLE 1
+#define CONFIG_DECODE_AUDIO_EXAMPLE 1
+#define CONFIG_DECODE_FILTER_AUDIO_EXAMPLE 0
+#define CONFIG_DECODE_FILTER_VIDEO_EXAMPLE 0
+#define CONFIG_DECODE_VIDEO_EXAMPLE 1
+#define CONFIG_DEMUX_DECODE_EXAMPLE 0
+#define CONFIG_ENCODE_AUDIO_EXAMPLE 1
+#define CONFIG_ENCODE_VIDEO_EXAMPLE 1
+#define CONFIG_EXTRACT_MVS_EXAMPLE 0
+#define CONFIG_FILTER_AUDIO_EXAMPLE 0
+#define CONFIG_HW_DECODE_EXAMPLE 0
+#define CONFIG_MUX_EXAMPLE 0
+#define CONFIG_QSV_DECODE_EXAMPLE 0
+#define CONFIG_REMUX_EXAMPLE 0
+#define CONFIG_RESAMPLE_AUDIO_EXAMPLE 0
+#define CONFIG_SCALE_VIDEO_EXAMPLE 0
+#define CONFIG_SHOW_METADATA_EXAMPLE 0
+#define CONFIG_TRANSCODE_AAC_EXAMPLE 0
+#define CONFIG_TRANSCODE_EXAMPLE 0
+#define CONFIG_VAAPI_ENCODE_EXAMPLE 0
+#define CONFIG_VAAPI_TRANSCODE_EXAMPLE 0
+#define CONFIG_QSV_TRANSCODE_EXAMPLE 0
+#define CONFIG_AVISYNTH 0
+#define CONFIG_FREI0R 0
+#define CONFIG_LIBCDIO 0
+#define CONFIG_LIBDAVS2 0
+#define CONFIG_LIBRUBBERBAND 0
+#define CONFIG_LIBVIDSTAB 0
+#define CONFIG_LIBX264 0
+#define CONFIG_LIBX265 0
+#define CONFIG_LIBXAVS 0
+#define CONFIG_LIBXAVS2 0
+#define CONFIG_LIBXVID 0
+#define CONFIG_DECKLINK 0
+#define CONFIG_LIBFDK_AAC 0
+#define CONFIG_LIBTLS 0
+#define CONFIG_GMP 0
+#define CONFIG_LIBARIBB24 0
+#define CONFIG_LIBLENSFUN 0
+#define CONFIG_LIBOPENCORE_AMRNB 0
+#define CONFIG_LIBOPENCORE_AMRWB 0
+#define CONFIG_LIBVO_AMRWBENC 0
+#define CONFIG_MBEDTLS 0
+#define CONFIG_RKMPP 0
+#define CONFIG_LIBSMBCLIENT 0
+#define CONFIG_CHROMAPRINT 0
+#define CONFIG_GCRYPT 0
+#define CONFIG_GNUTLS 0
+#define CONFIG_JNI 0
+#define CONFIG_LADSPA 0
+#define CONFIG_LCMS2 0
+#define CONFIG_LIBAOM 0
+#define CONFIG_LIBARIBCAPTION 0
+#define CONFIG_LIBASS 0
+#define CONFIG_LIBBLURAY 0
+#define CONFIG_LIBBS2B 0
+#define CONFIG_LIBCACA 0
+#define CONFIG_LIBCELT 0
+#define CONFIG_LIBCODEC2 0
+#define CONFIG_LIBDAV1D 0
+#define CONFIG_LIBDC1394 0
+#define CONFIG_LIBDRM 0
+#define CONFIG_LIBFLITE 0
+#define CONFIG_LIBFONTCONFIG 0
+#define CONFIG_LIBFREETYPE 0
+#define CONFIG_LIBFRIBIDI 0
+#define CONFIG_LIBHARFBUZZ 0
+#define CONFIG_LIBGLSLANG 0
+#define CONFIG_LIBGME 0
+#define CONFIG_LIBGSM 0
+#define CONFIG_LIBIEC61883 0
+#define CONFIG_LIBILBC 0
+#define CONFIG_LIBJACK 0
+#define CONFIG_LIBJXL 0
+#define CONFIG_LIBKLVANC 0
+#define CONFIG_LIBKVAZAAR 0
+#define CONFIG_LIBMODPLUG 0
+#define CONFIG_LIBMP3LAME 0
+#define CONFIG_LIBMYSOFA 0
+#define CONFIG_LIBOPENCV 0
+#define CONFIG_LIBOPENH264 0
+#define CONFIG_LIBOPENJPEG 0
+#define CONFIG_LIBOPENMPT 0
+#define CONFIG_LIBOPENVINO 0
+#define CONFIG_LIBOPUS 0
+#define CONFIG_LIBPLACEBO 0
+#define CONFIG_LIBPULSE 0
+#define CONFIG_LIBRABBITMQ 0
+#define CONFIG_LIBRAV1E 0
+#define CONFIG_LIBRIST 0
+#define CONFIG_LIBRSVG 0
+#define CONFIG_LIBRTMP 0
+#define CONFIG_LIBSHADERC 0
+#define CONFIG_LIBSHINE 0
+#define CONFIG_LIBSMBCLIENT 0
+#define CONFIG_LIBSNAPPY 0
+#define CONFIG_LIBSOXR 0
+#define CONFIG_LIBSPEEX 0
+#define CONFIG_LIBSRT 0
+#define CONFIG_LIBSSH 0
+#define CONFIG_LIBSVTAV1 0
+#define CONFIG_LIBTENSORFLOW 0
+#define CONFIG_LIBTESSERACT 0
+#define CONFIG_LIBTHEORA 0
+#define CONFIG_LIBTWOLAME 0
+#define CONFIG_LIBUAVS3D 0
+#define CONFIG_LIBV4L2 0
+#define CONFIG_LIBVMAF 0
+#define CONFIG_LIBVORBIS 0
+#define CONFIG_LIBVPX 0
+#define CONFIG_LIBWEBP 0
+#define CONFIG_LIBXML2 0
+#define CONFIG_LIBZIMG 0
+#define CONFIG_LIBZMQ 0
+#define CONFIG_LIBZVBI 0
+#define CONFIG_LV2 0
+#define CONFIG_MEDIACODEC 0
+#define CONFIG_OPENAL 0
+#define CONFIG_OPENGL 0
+#define CONFIG_OPENSSL 0
+#define CONFIG_POCKETSPHINX 0
+#define CONFIG_VAPOURSYNTH 0
+#define CONFIG_ALSA 0
+#define CONFIG_APPKIT 0
+#define CONFIG_AVFOUNDATION 0
+#define CONFIG_BZLIB 0
+#define CONFIG_COREIMAGE 0
+#define CONFIG_ICONV 0
+#define CONFIG_LIBXCB 0
+#define CONFIG_LIBXCB_SHM 0
+#define CONFIG_LIBXCB_SHAPE 0
+#define CONFIG_LIBXCB_XFIXES 0
+#define CONFIG_LZMA 0
+#define CONFIG_MEDIAFOUNDATION 0
+#define CONFIG_METAL 0
+#define CONFIG_SCHANNEL 0
+#define CONFIG_SDL2 0
+#define CONFIG_SECURETRANSPORT 0
+#define CONFIG_SNDIO 0
+#define CONFIG_XLIB 0
+#define CONFIG_ZLIB 0
+#define CONFIG_CUDA_NVCC 0
+#define CONFIG_CUDA_SDK 0
+#define CONFIG_LIBNPP 0
+#define CONFIG_LIBMFX 0
+#define CONFIG_LIBVPL 0
+#define CONFIG_MMAL 0
+#define CONFIG_OMX 0
+#define CONFIG_OPENCL 0
+#define CONFIG_AMF 0
+#define CONFIG_AUDIOTOOLBOX 0
+#define CONFIG_CRYSTALHD 0
+#define CONFIG_CUDA 0
+#define CONFIG_CUDA_LLVM 0
+#define CONFIG_CUVID 0
+#define CONFIG_D3D11VA 0
+#define CONFIG_DXVA2 0
+#define CONFIG_FFNVCODEC 0
+#define CONFIG_NVDEC 0
+#define CONFIG_NVENC 0
+#define CONFIG_VAAPI 0
+#define CONFIG_VDPAU 0
+#define CONFIG_VIDEOTOOLBOX 0
+#define CONFIG_VULKAN 0
+#define CONFIG_V4L2_M2M 0
+#define CONFIG_FTRAPV 0
+#define CONFIG_GRAY 0
+#define CONFIG_HARDCODED_TABLES 0
+#define CONFIG_OMX_RPI 0
+#define CONFIG_RUNTIME_CPUDETECT 1
+#define CONFIG_SAFE_BITSTREAM_READER 1
+#define CONFIG_SHARED 1
+#define CONFIG_SMALL 0
+#define CONFIG_STATIC 0
+#define CONFIG_SWSCALE_ALPHA 1
+#define CONFIG_GPL 0
+#define CONFIG_NONFREE 0
+#define CONFIG_VERSION3 0
+#define CONFIG_AVDEVICE 0
+#define CONFIG_AVFILTER 0
+#define CONFIG_SWSCALE 0
+#define CONFIG_POSTPROC 0
+#define CONFIG_AVFORMAT 0
+#define CONFIG_AVCODEC 1
+#define CONFIG_SWRESAMPLE 0
+#define CONFIG_AVUTIL 1
+#define CONFIG_FFPLAY 0
+#define CONFIG_FFPROBE 0
+#define CONFIG_FFMPEG 0
+#define CONFIG_DWT 0
+#define CONFIG_ERROR_RESILIENCE 0
+#define CONFIG_FAAN 1
+#define CONFIG_FAST_UNALIGNED 1
+#define CONFIG_LSP 0
+#define CONFIG_PIXELUTILS 0
+#define CONFIG_NETWORK 0
+#define CONFIG_AUTODETECT 0
+#define CONFIG_FONTCONFIG 0
+#define CONFIG_LARGE_TESTS 1
+#define CONFIG_LINUX_PERF 0
+#define CONFIG_MACOS_KPERF 0
+#define CONFIG_MEMORY_POISONING 0
+#define CONFIG_NEON_CLOBBER_TEST 0
+#define CONFIG_OSSFUZZ 0
+#define CONFIG_PIC 1
+#define CONFIG_PTX_COMPRESSION 0
+#define CONFIG_THUMB 0
+#define CONFIG_VALGRIND_BACKTRACE 0
+#define CONFIG_XMM_CLOBBER_TEST 0
+#define CONFIG_BSFS 0
+#define CONFIG_DECODERS 1
+#define CONFIG_ENCODERS 0
+#define CONFIG_HWACCELS 0
+#define CONFIG_PARSERS 1
+#define CONFIG_INDEVS 0
+#define CONFIG_OUTDEVS 0
+#define CONFIG_FILTERS 0
+#define CONFIG_DEMUXERS 0
+#define CONFIG_MUXERS 0
+#define CONFIG_PROTOCOLS 0
+#define CONFIG_AANDCTTABLES 0
+#define CONFIG_AC3DSP 0
+#define CONFIG_ADTS_HEADER 0
+#define CONFIG_ATSC_A53 0
+#define CONFIG_AUDIO_FRAME_QUEUE 0
+#define CONFIG_AUDIODSP 0
+#define CONFIG_BLOCKDSP 0
+#define CONFIG_BSWAPDSP 0
+#define CONFIG_CABAC 0
+#define CONFIG_CBS 0
+#define CONFIG_CBS_AV1 0
+#define CONFIG_CBS_H264 0
+#define CONFIG_CBS_H265 0
+#define CONFIG_CBS_H266 0
+#define CONFIG_CBS_JPEG 0
+#define CONFIG_CBS_MPEG2 0
+#define CONFIG_CBS_VP9 0
+#define CONFIG_DEFLATE_WRAPPER 0
+#define CONFIG_DIRAC_PARSE 0
+#define CONFIG_DNN 0
+#define CONFIG_DOVI_RPU 0
+#define CONFIG_DVPROFILE 0
+#define CONFIG_EVCPARSE 0
+#define CONFIG_EXIF 0
+#define CONFIG_FAANDCT 1
+#define CONFIG_FAANIDCT 1
+#define CONFIG_FDCTDSP 1
+#define CONFIG_FMTCONVERT 0
+#define CONFIG_FRAME_THREAD_ENCODER 0
+#define CONFIG_G722DSP 0
+#define CONFIG_GOLOMB 0
+#define CONFIG_GPLV3 0
+#define CONFIG_H263DSP 0
+#define CONFIG_H264CHROMA 0
+#define CONFIG_H264DSP 0
+#define CONFIG_H264PARSE 0
+#define CONFIG_H264PRED 1
+#define CONFIG_H264QPEL 0
+#define CONFIG_H264_SEI 0
+#define CONFIG_HEVCPARSE 0
+#define CONFIG_HEVC_SEI 0
+#define CONFIG_HPELDSP 0
+#define CONFIG_HUFFMAN 0
+#define CONFIG_HUFFYUVDSP 0
+#define CONFIG_HUFFYUVENCDSP 0
+#define CONFIG_IDCTDSP 1
+#define CONFIG_IIRFILTER 0
+#define CONFIG_INFLATE_WRAPPER 0
+#define CONFIG_INTRAX8 0
+#define CONFIG_ISO_MEDIA 0
+#define CONFIG_IVIDSP 0
+#define CONFIG_JPEGTABLES 0
+#define CONFIG_LGPLV3 0
+#define CONFIG_LIBX262 0
+#define CONFIG_LLAUDDSP 0
+#define CONFIG_LLVIDDSP 0
+#define CONFIG_LLVIDENCDSP 0
+#define CONFIG_LPC 0
+#define CONFIG_LZF 0
+#define CONFIG_ME_CMP 0
+#define CONFIG_MPEG_ER 0
+#define CONFIG_MPEGAUDIO 0
+#define CONFIG_MPEGAUDIODSP 0
+#define CONFIG_MPEGAUDIOHEADER 0
+#define CONFIG_MPEG4AUDIO 0
+#define CONFIG_MPEGVIDEO 0
+#define CONFIG_MPEGVIDEODEC 0
+#define CONFIG_MPEGVIDEOENC 0
+#define CONFIG_MSMPEG4DEC 0
+#define CONFIG_MSMPEG4ENC 0
+#define CONFIG_MSS34DSP 0
+#define CONFIG_PIXBLOCKDSP 0
+#define CONFIG_QPELDSP 0
+#define CONFIG_QSV 0
+#define CONFIG_QSVDEC 0
+#define CONFIG_QSVENC 0
+#define CONFIG_QSVVPP 0
+#define CONFIG_RANGECODER 0
+#define CONFIG_RIFFDEC 0
+#define CONFIG_RIFFENC 0
+#define CONFIG_RTPDEC 0
+#define CONFIG_RTPENC_CHAIN 0
+#define CONFIG_RV34DSP 0
+#define CONFIG_SCENE_SAD 0
+#define CONFIG_SINEWIN 0
+#define CONFIG_SNAPPY 0
+#define CONFIG_SRTP 0
+#define CONFIG_STARTCODE 0
+#define CONFIG_TEXTUREDSP 0
+#define CONFIG_TEXTUREDSPENC 0
+#define CONFIG_TPELDSP 0
+#define CONFIG_VAAPI_1 0
+#define CONFIG_VAAPI_ENCODE 0
+#define CONFIG_VC1DSP 0
+#define CONFIG_VIDEODSP 1
+#define CONFIG_VP3DSP 0
+#define CONFIG_VP56DSP 0
+#define CONFIG_VP8DSP 1
+#define CONFIG_WMA_FREQS 0
+#define CONFIG_WMV2DSP 0
+#endif /* FFMPEG_CONFIG_H */
diff --git a/media/ffvpx/libavcodec/moz.build b/media/ffvpx/libavcodec/moz.build
index 71fac08dba..4efcefc4a3 100644
--- a/media/ffvpx/libavcodec/moz.build
+++ b/media/ffvpx/libavcodec/moz.build
@@ -13,6 +13,8 @@ if CONFIG['FFVPX_ASFLAGS']:
 
 if CONFIG['CPU_ARCH'] == 'aarch64':
     DIRS += ['aarch64']
+elif CONFIG['CPU_ARCH'].startswith('ppc'):
+    DIRS += ['ppc']
 
 SharedLibrary('mozavcodec')
 SOURCES += [
diff --git a/media/ffvpx/libavcodec/ppc/hpeldsp_altivec.c b/media/ffvpx/libavcodec/ppc/hpeldsp_altivec.c
new file mode 100644
index 0000000000..a531b6b6ec
--- /dev/null
+++ b/media/ffvpx/libavcodec/ppc/hpeldsp_altivec.c
@@ -0,0 +1,386 @@
+/*
+ * Copyright (c) 2002 Brian Foley
+ * Copyright (c) 2002 Dieter Shirley
+ * Copyright (c) 2003-2004 Romain Dolbeau <romain@dolbeau.org>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "config.h"
+
+#include "libavutil/attributes.h"
+#include "libavutil/cpu.h"
+#include "libavutil/ppc/cpu.h"
+#include "libavutil/ppc/util_altivec.h"
+
+#include "libavcodec/hpeldsp.h"
+
+#include "hpeldsp_altivec.h"
+
+#if HAVE_ALTIVEC
+/* next one assumes that ((line_size % 16) == 0) */
+void ff_put_pixels16_altivec(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)
+{
+    register vector unsigned char pixelsv1;
+    register vector unsigned char pixelsv1B;
+    register vector unsigned char pixelsv1C;
+    register vector unsigned char pixelsv1D;
+
+    int i;
+    register ptrdiff_t line_size_2 = line_size << 1;
+    register ptrdiff_t line_size_3 = line_size + line_size_2;
+    register ptrdiff_t line_size_4 = line_size << 2;
+
+// hand-unrolling the loop by 4 gains about 15%
+// mininum execution time goes from 74 to 60 cycles
+// it's faster than -funroll-loops, but using
+// -funroll-loops w/ this is bad - 74 cycles again.
+// all this is on a 7450, tuning for the 7450
+    for (i = 0; i < h; i += 4) {
+        pixelsv1  = unaligned_load( 0, pixels);
+        pixelsv1B = unaligned_load(line_size, pixels);
+        pixelsv1C = unaligned_load(line_size_2, pixels);
+        pixelsv1D = unaligned_load(line_size_3, pixels);
+        VEC_ST(pixelsv1, 0, (unsigned char*)block);
+        VEC_ST(pixelsv1B, line_size, (unsigned char*)block);
+        VEC_ST(pixelsv1C, line_size_2, (unsigned char*)block);
+        VEC_ST(pixelsv1D, line_size_3, (unsigned char*)block);
+        pixels+=line_size_4;
+        block +=line_size_4;
+    }
+}
+
+/* next one assumes that ((line_size % 16) == 0) */
+#define op_avg(a,b)  a = ( ((a)|(b)) - ((((a)^(b))&0xFEFEFEFEUL)>>1) )
+void ff_avg_pixels16_altivec(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)
+{
+    register vector unsigned char pixelsv, blockv;
+
+    int i;
+    for (i = 0; i < h; i++) {
+        blockv = vec_ld(0, block);
+        pixelsv = VEC_LD( 0, pixels);
+        blockv = vec_avg(blockv,pixelsv);
+        vec_st(blockv, 0, (unsigned char*)block);
+        pixels+=line_size;
+        block +=line_size;
+    }
+}
+
+/* next one assumes that ((line_size % 8) == 0) */
+static void avg_pixels8_altivec(uint8_t * block, const uint8_t * pixels, ptrdiff_t line_size, int h)
+{
+    register vector unsigned char pixelsv, blockv;
+    int i;
+
+   for (i = 0; i < h; i++) {
+       /* block is 8 bytes-aligned, so we're either in the
+          left block (16 bytes-aligned) or in the right block (not) */
+       int rightside = ((unsigned long)block & 0x0000000F);
+
+       blockv = vec_ld(0, block);
+       pixelsv = VEC_LD( 0, pixels);
+
+       if (rightside) {
+           pixelsv = vec_perm(blockv, pixelsv, vcprm(0,1,s0,s1));
+       } else {
+           pixelsv = vec_perm(blockv, pixelsv, vcprm(s0,s1,2,3));
+       }
+
+       blockv = vec_avg(blockv, pixelsv);
+
+       vec_st(blockv, 0, block);
+
+       pixels += line_size;
+       block += line_size;
+   }
+}
+
+/* next one assumes that ((line_size % 8) == 0) */
+static void put_pixels8_xy2_altivec(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)
+{
+    register int i;
+    register vector unsigned char pixelsv1, pixelsv2, pixelsavg;
+    register vector unsigned char blockv;
+    register vector unsigned short pixelssum1, pixelssum2, temp3;
+    register const vector unsigned char vczero = (const vector unsigned char)vec_splat_u8(0);
+    register const vector unsigned short vctwo = (const vector unsigned short)vec_splat_u16(2);
+
+    pixelsv1 = VEC_LD(0, pixels);
+    pixelsv2 = VEC_LD(1, pixels);
+    pixelsv1 = VEC_MERGEH(vczero, pixelsv1);
+    pixelsv2 = VEC_MERGEH(vczero, pixelsv2);
+
+    pixelssum1 = vec_add((vector unsigned short)pixelsv1,
+                         (vector unsigned short)pixelsv2);
+    pixelssum1 = vec_add(pixelssum1, vctwo);
+
+    for (i = 0; i < h ; i++) {
+        int rightside = ((unsigned long)block & 0x0000000F);
+        blockv = vec_ld(0, block);
+
+        pixelsv1 = unaligned_load(line_size, pixels);
+        pixelsv2 = unaligned_load(line_size+1, pixels);
+        pixelsv1 = VEC_MERGEH(vczero, pixelsv1);
+        pixelsv2 = VEC_MERGEH(vczero, pixelsv2);
+        pixelssum2 = vec_add((vector unsigned short)pixelsv1,
+                             (vector unsigned short)pixelsv2);
+        temp3 = vec_add(pixelssum1, pixelssum2);
+        temp3 = vec_sra(temp3, vctwo);
+        pixelssum1 = vec_add(pixelssum2, vctwo);
+        pixelsavg = vec_packsu(temp3, (vector unsigned short) vczero);
+
+        if (rightside) {
+            blockv = vec_perm(blockv, pixelsavg, vcprm(0, 1, s0, s1));
+        } else {
+            blockv = vec_perm(blockv, pixelsavg, vcprm(s0, s1, 2, 3));
+        }
+
+        vec_st(blockv, 0, block);
+
+        block += line_size;
+        pixels += line_size;
+    }
+}
+
+/* next one assumes that ((line_size % 8) == 0) */
+static void put_no_rnd_pixels8_xy2_altivec(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)
+{
+    register int i;
+    register vector unsigned char pixelsv1, pixelsv2, pixelsavg;
+    register vector unsigned char blockv;
+    register vector unsigned short pixelssum1, pixelssum2, temp3;
+    register const vector unsigned char vczero = (const vector unsigned char)vec_splat_u8(0);
+    register const vector unsigned short vcone = (const vector unsigned short)vec_splat_u16(1);
+    register const vector unsigned short vctwo = (const vector unsigned short)vec_splat_u16(2);
+
+    pixelsv1 = VEC_LD(0, pixels);
+    pixelsv2 = VEC_LD(1, pixels);
+    pixelsv1 = VEC_MERGEH(vczero, pixelsv1);
+    pixelsv2 = VEC_MERGEH(vczero, pixelsv2);
+    pixelssum1 = vec_add((vector unsigned short)pixelsv1,
+                         (vector unsigned short)pixelsv2);
+    pixelssum1 = vec_add(pixelssum1, vcone);
+
+    for (i = 0; i < h ; i++) {
+        int rightside = ((unsigned long)block & 0x0000000F);
+        blockv = vec_ld(0, block);
+
+        pixelsv1 = unaligned_load(line_size, pixels);
+        pixelsv2 = unaligned_load(line_size+1, pixels);
+        pixelsv1 = VEC_MERGEH(vczero, pixelsv1);
+        pixelsv2 = VEC_MERGEH(vczero, pixelsv2);
+        pixelssum2 = vec_add((vector unsigned short)pixelsv1,
+                             (vector unsigned short)pixelsv2);
+        temp3 = vec_add(pixelssum1, pixelssum2);
+        temp3 = vec_sra(temp3, vctwo);
+        pixelssum1 = vec_add(pixelssum2, vcone);
+        pixelsavg = vec_packsu(temp3, (vector unsigned short) vczero);
+
+        if (rightside) {
+            blockv = vec_perm(blockv, pixelsavg, vcprm(0, 1, s0, s1));
+        } else {
+            blockv = vec_perm(blockv, pixelsavg, vcprm(s0, s1, 2, 3));
+        }
+
+        vec_st(blockv, 0, block);
+
+        block += line_size;
+        pixels += line_size;
+    }
+}
+
+/* next one assumes that ((line_size % 16) == 0) */
+static void put_pixels16_xy2_altivec(uint8_t * block, const uint8_t * pixels, ptrdiff_t line_size, int h)
+{
+    register int i;
+    register vector unsigned char pixelsv1, pixelsv2, pixelsv3, pixelsv4;
+    register vector unsigned char blockv;
+    register vector unsigned short temp3, temp4,
+        pixelssum1, pixelssum2, pixelssum3, pixelssum4;
+    register const vector unsigned char vczero = (const vector unsigned char)vec_splat_u8(0);
+    register const vector unsigned short vctwo = (const vector unsigned short)vec_splat_u16(2);
+
+    pixelsv1 = VEC_LD(0, pixels);
+    pixelsv2 = VEC_LD(1, pixels);
+    pixelsv3 = VEC_MERGEL(vczero, pixelsv1);
+    pixelsv4 = VEC_MERGEL(vczero, pixelsv2);
+    pixelsv1 = VEC_MERGEH(vczero, pixelsv1);
+    pixelsv2 = VEC_MERGEH(vczero, pixelsv2);
+    pixelssum3 = vec_add((vector unsigned short)pixelsv3,
+                         (vector unsigned short)pixelsv4);
+    pixelssum3 = vec_add(pixelssum3, vctwo);
+    pixelssum1 = vec_add((vector unsigned short)pixelsv1,
+                         (vector unsigned short)pixelsv2);
+    pixelssum1 = vec_add(pixelssum1, vctwo);
+
+    for (i = 0; i < h ; i++) {
+        blockv = vec_ld(0, block);
+
+        pixelsv1 = unaligned_load(line_size, pixels);
+        pixelsv2 = unaligned_load(line_size+1, pixels);
+
+        pixelsv3 = VEC_MERGEL(vczero, pixelsv1);
+        pixelsv4 = VEC_MERGEL(vczero, pixelsv2);
+        pixelsv1 = VEC_MERGEH(vczero, pixelsv1);
+        pixelsv2 = VEC_MERGEH(vczero, pixelsv2);
+        pixelssum4 = vec_add((vector unsigned short)pixelsv3,
+                             (vector unsigned short)pixelsv4);
+        pixelssum2 = vec_add((vector unsigned short)pixelsv1,
+                             (vector unsigned short)pixelsv2);
+        temp4 = vec_add(pixelssum3, pixelssum4);
+        temp4 = vec_sra(temp4, vctwo);
+        temp3 = vec_add(pixelssum1, pixelssum2);
+        temp3 = vec_sra(temp3, vctwo);
+
+        pixelssum3 = vec_add(pixelssum4, vctwo);
+        pixelssum1 = vec_add(pixelssum2, vctwo);
+
+        blockv = vec_packsu(temp3, temp4);
+
+        vec_st(blockv, 0, block);
+
+        block += line_size;
+        pixels += line_size;
+    }
+}
+
+/* next one assumes that ((line_size % 16) == 0) */
+static void put_no_rnd_pixels16_xy2_altivec(uint8_t * block, const uint8_t * pixels, ptrdiff_t line_size, int h)
+{
+    register int i;
+    register vector unsigned char pixelsv1, pixelsv2, pixelsv3, pixelsv4;
+    register vector unsigned char blockv;
+    register vector unsigned short temp3, temp4,
+        pixelssum1, pixelssum2, pixelssum3, pixelssum4;
+    register const vector unsigned char vczero = (const vector unsigned char)vec_splat_u8(0);
+    register const vector unsigned short vcone = (const vector unsigned short)vec_splat_u16(1);
+    register const vector unsigned short vctwo = (const vector unsigned short)vec_splat_u16(2);
+
+    pixelsv1 = VEC_LD(0, pixels);
+    pixelsv2 = VEC_LD(1, pixels);
+    pixelsv3 = VEC_MERGEL(vczero, pixelsv1);
+    pixelsv4 = VEC_MERGEL(vczero, pixelsv2);
+    pixelsv1 = VEC_MERGEH(vczero, pixelsv1);
+    pixelsv2 = VEC_MERGEH(vczero, pixelsv2);
+    pixelssum3 = vec_add((vector unsigned short)pixelsv3,
+                         (vector unsigned short)pixelsv4);
+    pixelssum3 = vec_add(pixelssum3, vcone);
+    pixelssum1 = vec_add((vector unsigned short)pixelsv1,
+                         (vector unsigned short)pixelsv2);
+    pixelssum1 = vec_add(pixelssum1, vcone);
+
+    for (i = 0; i < h ; i++) {
+        pixelsv1 = unaligned_load(line_size, pixels);
+        pixelsv2 = unaligned_load(line_size+1, pixels);
+
+        pixelsv3 = VEC_MERGEL(vczero, pixelsv1);
+        pixelsv4 = VEC_MERGEL(vczero, pixelsv2);
+        pixelsv1 = VEC_MERGEH(vczero, pixelsv1);
+        pixelsv2 = VEC_MERGEH(vczero, pixelsv2);
+        pixelssum4 = vec_add((vector unsigned short)pixelsv3,
+                             (vector unsigned short)pixelsv4);
+        pixelssum2 = vec_add((vector unsigned short)pixelsv1,
+                             (vector unsigned short)pixelsv2);
+        temp4 = vec_add(pixelssum3, pixelssum4);
+        temp4 = vec_sra(temp4, vctwo);
+        temp3 = vec_add(pixelssum1, pixelssum2);
+        temp3 = vec_sra(temp3, vctwo);
+
+        pixelssum3 = vec_add(pixelssum4, vcone);
+        pixelssum1 = vec_add(pixelssum2, vcone);
+
+        blockv = vec_packsu(temp3, temp4);
+
+        VEC_ST(blockv, 0, block);
+
+        block += line_size;
+        pixels += line_size;
+    }
+}
+
+/* next one assumes that ((line_size % 8) == 0) */
+static void avg_pixels8_xy2_altivec(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)
+{
+    register int i;
+    register vector unsigned char pixelsv1, pixelsv2, pixelsavg;
+    register vector unsigned char blockv, blocktemp;
+    register vector unsigned short pixelssum1, pixelssum2, temp3;
+
+    register const vector unsigned char vczero = (const vector unsigned char)
+                                        vec_splat_u8(0);
+    register const vector unsigned short vctwo = (const vector unsigned short)
+                                        vec_splat_u16(2);
+
+    pixelsv1 = VEC_LD(0, pixels);
+    pixelsv2 = VEC_LD(1, pixels);
+    pixelsv1 = VEC_MERGEH(vczero, pixelsv1);
+    pixelsv2 = VEC_MERGEH(vczero, pixelsv2);
+    pixelssum1 = vec_add((vector unsigned short)pixelsv1,
+                         (vector unsigned short)pixelsv2);
+    pixelssum1 = vec_add(pixelssum1, vctwo);
+
+    for (i = 0; i < h ; i++) {
+        int rightside = ((unsigned long)block & 0x0000000F);
+        blockv = vec_ld(0, block);
+
+        pixelsv1 = unaligned_load(line_size, pixels);
+        pixelsv2 = unaligned_load(line_size+1, pixels);
+
+        pixelsv1 = VEC_MERGEH(vczero, pixelsv1);
+        pixelsv2 = VEC_MERGEH(vczero, pixelsv2);
+        pixelssum2 = vec_add((vector unsigned short)pixelsv1,
+                             (vector unsigned short)pixelsv2);
+        temp3 = vec_add(pixelssum1, pixelssum2);
+        temp3 = vec_sra(temp3, vctwo);
+        pixelssum1 = vec_add(pixelssum2, vctwo);
+        pixelsavg = vec_packsu(temp3, (vector unsigned short) vczero);
+
+        if (rightside) {
+            blocktemp = vec_perm(blockv, pixelsavg, vcprm(0, 1, s0, s1));
+        } else {
+            blocktemp = vec_perm(blockv, pixelsavg, vcprm(s0, s1, 2, 3));
+        }
+
+        blockv = vec_avg(blocktemp, blockv);
+        vec_st(blockv, 0, block);
+
+        block += line_size;
+        pixels += line_size;
+    }
+}
+#endif /* HAVE_ALTIVEC */
+
+av_cold void ff_hpeldsp_init_ppc(HpelDSPContext *c, int flags)
+{
+#if HAVE_ALTIVEC
+    if (!PPC_ALTIVEC(av_get_cpu_flags()))
+        return;
+
+    c->avg_pixels_tab[0][0]        = ff_avg_pixels16_altivec;
+    c->avg_pixels_tab[1][0]        = avg_pixels8_altivec;
+    c->avg_pixels_tab[1][3]        = avg_pixels8_xy2_altivec;
+
+    c->put_pixels_tab[0][0]        = ff_put_pixels16_altivec;
+    c->put_pixels_tab[1][3]        = put_pixels8_xy2_altivec;
+    c->put_pixels_tab[0][3]        = put_pixels16_xy2_altivec;
+
+    c->put_no_rnd_pixels_tab[0][0] = ff_put_pixels16_altivec;
+    c->put_no_rnd_pixels_tab[1][3] = put_no_rnd_pixels8_xy2_altivec;
+    c->put_no_rnd_pixels_tab[0][3] = put_no_rnd_pixels16_xy2_altivec;
+#endif /* HAVE_ALTIVEC */
+}
diff --git a/media/ffvpx/libavcodec/ppc/hpeldsp_altivec.h b/media/ffvpx/libavcodec/ppc/hpeldsp_altivec.h
new file mode 100644
index 0000000000..590809f539
--- /dev/null
+++ b/media/ffvpx/libavcodec/ppc/hpeldsp_altivec.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright (c) 2002 Brian Foley
+ * Copyright (c) 2002 Dieter Shirley
+ * Copyright (c) 2003-2004 Romain Dolbeau <romain@dolbeau.org>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVCODEC_PPC_HPELDSP_ALTIVEC_H
+#define AVCODEC_PPC_HPELDSP_ALTIVEC_H
+
+#include <stddef.h>
+#include <stdint.h>
+
+void ff_avg_pixels16_altivec(uint8_t *block, const uint8_t *pixels,
+                             ptrdiff_t line_size, int h);
+void ff_put_pixels16_altivec(uint8_t *block, const uint8_t *pixels,
+                             ptrdiff_t line_size, int h);
+
+#endif /* AVCODEC_PPC_HPELDSP_ALTIVEC_H */
diff --git a/media/ffvpx/libavcodec/ppc/mathops.h b/media/ffvpx/libavcodec/ppc/mathops.h
new file mode 100644
index 0000000000..1be5f0af89
--- /dev/null
+++ b/media/ffvpx/libavcodec/ppc/mathops.h
@@ -0,0 +1,79 @@
+/*
+ * simple math operations
+ * Copyright (c) 2001, 2002 Fabrice Bellard
+ * Copyright (c) 2006 Michael Niedermayer <michaelni@gmx.at> et al
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVCODEC_PPC_MATHOPS_H
+#define AVCODEC_PPC_MATHOPS_H
+
+#include <stdint.h>
+#include "config.h"
+#include "libavutil/common.h"
+
+#if HAVE_PPC4XX == 1
+/* signed 16x16 -> 32 multiply add accumulate */
+#define MAC16(rt, ra, rb) \
+    __asm__ ("maclhw %0, %2, %3" : "=r" (rt) : "0" (rt), "r" (ra), "r" (rb));
+
+/* signed 16x16 -> 32 multiply */
+#define MUL16(ra, rb) \
+    ({ int __rt; \
+    __asm__ ("mullhw %0, %1, %2" : "=r" (__rt) : "r" (ra), "r" (rb)); \
+    __rt; })
+#endif
+
+#define MULH MULH
+static inline av_const int MULH(int a, int b){
+    int r;
+    __asm__ ("mulhw %0, %1, %2" : "=r"(r) : "r"(a), "r"(b));
+    return r;
+}
+
+#if !ARCH_PPC64
+static inline av_const int64_t MAC64(int64_t d, int a, int b)
+{
+    union { uint64_t x; unsigned hl[2]; } x = { d };
+    int h, l;
+    __asm__ ("mullw %3, %4, %5   \n\t"
+             "mulhw %2, %4, %5   \n\t"
+             "addc  %1, %1, %3   \n\t"
+             "adde  %0, %0, %2   \n\t"
+             : "+r"(x.hl[0]), "+r"(x.hl[1]), "=&r"(h), "=&r"(l)
+             : "r"(a), "r"(b));
+    return x.x;
+}
+#define MAC64(d, a, b) ((d) = MAC64(d, a, b))
+
+static inline av_const int64_t MLS64(int64_t d, int a, int b)
+{
+    union { uint64_t x; unsigned hl[2]; } x = { d };
+    int h, l;
+    __asm__ ("mullw %3, %4, %5   \n\t"
+             "mulhw %2, %4, %5   \n\t"
+             "subfc %1, %3, %1   \n\t"
+             "subfe %0, %2, %0   \n\t"
+             : "+r"(x.hl[0]), "+r"(x.hl[1]), "=&r"(h), "=&r"(l)
+             : "r"(a), "r"(b));
+    return x.x;
+}
+#define MLS64(d, a, b) ((d) = MLS64(d, a, b))
+#endif
+
+#endif /* AVCODEC_PPC_MATHOPS_H */
diff --git a/media/ffvpx/libavcodec/ppc/moz.build b/media/ffvpx/libavcodec/ppc/moz.build
new file mode 100644
index 0000000000..68db3f1dd8
--- /dev/null
+++ b/media/ffvpx/libavcodec/ppc/moz.build
@@ -0,0 +1,14 @@
+# -*- Mode: python; indent-tabs-mode: nil; tab-width: 40 -*-
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+
+SOURCES += [
+    'hpeldsp_altivec.c',
+    'videodsp.c',
+    'vp8dsp_altivec.c'
+]
+
+FINAL_LIBRARY = 'mozavcodec'
+
+include('/media/ffvpx/ffvpxcommon.mozbuild')
diff --git a/media/ffvpx/libavcodec/ppc/videodsp.c b/media/ffvpx/libavcodec/ppc/videodsp.c
new file mode 100644
index 0000000000..a7ab5a6a42
--- /dev/null
+++ b/media/ffvpx/libavcodec/ppc/videodsp.c
@@ -0,0 +1,36 @@
+/*
+ * Copyright (c) 2003-2004 Romain Dolbeau
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/attributes.h"
+#include "libavcodec/videodsp.h"
+
+static void prefetch_ppc(const uint8_t *mem, ptrdiff_t stride, int h)
+{
+    register const uint8_t *p = mem;
+    do {
+        __asm__ volatile ("dcbt 0,%0" : : "r" (p));
+        p += stride;
+    } while(--h);
+}
+
+av_cold void ff_videodsp_init_ppc(VideoDSPContext *ctx, int bpc)
+{
+    ctx->prefetch = prefetch_ppc;
+}
diff --git a/media/ffvpx/libavcodec/ppc/vp8dsp_altivec.c b/media/ffvpx/libavcodec/ppc/vp8dsp_altivec.c
new file mode 100644
index 0000000000..fbfcd2ff5f
--- /dev/null
+++ b/media/ffvpx/libavcodec/ppc/vp8dsp_altivec.c
@@ -0,0 +1,362 @@
+/*
+ * VP8 compatible video decoder
+ *
+ * Copyright (C) 2010 David Conrad
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "config.h"
+
+#include "libavutil/attributes.h"
+#include "libavutil/cpu.h"
+#include "libavutil/mem_internal.h"
+#include "libavutil/ppc/cpu.h"
+#include "libavutil/ppc/util_altivec.h"
+
+#include "libavcodec/vp8dsp.h"
+
+#include "hpeldsp_altivec.h"
+
+#if HAVE_ALTIVEC == 1
+#define REPT4(...) { __VA_ARGS__, __VA_ARGS__, __VA_ARGS__, __VA_ARGS__ }
+
+// h subpel filter uses msum to multiply+add 4 pixel taps at once
+static const vec_s8 h_subpel_filters_inner[7] =
+{
+    REPT4( -6, 123,  12,  -1),
+    REPT4(-11, 108,  36,  -8),
+    REPT4( -9,  93,  50,  -6),
+    REPT4(-16,  77,  77, -16),
+    REPT4( -6,  50,  93,  -9),
+    REPT4( -8,  36, 108, -11),
+    REPT4( -1,  12, 123,  -6),
+};
+
+// for 6tap filters, these are the outer two taps
+// The zeros mask off pixels 4-7 when filtering 0-3
+// and vice-versa
+static const vec_s8 h_subpel_filters_outer[3] =
+{
+    REPT4(0, 0, 2, 1),
+    REPT4(0, 0, 3, 3),
+    REPT4(0, 0, 1, 2),
+};
+
+#define LOAD_H_SUBPEL_FILTER(i) \
+    vec_s8 filter_inner  = h_subpel_filters_inner[i]; \
+    vec_s8 filter_outerh = h_subpel_filters_outer[(i)>>1]; \
+    vec_s8 filter_outerl = vec_sld(filter_outerh, filter_outerh, 2)
+
+#if HAVE_BIGENDIAN == 1
+#define GET_PIXHL(offset)                   \
+    a = vec_ld((offset)-is6tap-1, src);     \
+    b = vec_ld((offset)-is6tap-1+15, src);  \
+    pixh  = vec_perm(a, b, permh##offset);  \
+    pixl  = vec_perm(a, b, perml##offset)
+
+#define GET_OUTER(offset) outer = vec_perm(a, b, perm_6tap##offset)
+#else
+#define GET_PIXHL(offset)                   \
+    a = vec_vsx_ld((offset)-is6tap-1, src); \
+    pixh  = vec_perm(a, a, perm_inner);     \
+    pixl  = vec_perm(a, a, vec_add(perm_inner, vec_splat_u8(4)))
+
+#define GET_OUTER(offset) outer = vec_perm(a, a, perm_outer)
+#endif
+
+#define FILTER_H(dstv, off) \
+    GET_PIXHL(off);                            \
+    filth = vec_msum(filter_inner, pixh, c64); \
+    filtl = vec_msum(filter_inner, pixl, c64); \
+\
+    if (is6tap) { \
+        GET_OUTER(off);                                \
+        filth = vec_msum(filter_outerh, outer, filth); \
+        filtl = vec_msum(filter_outerl, outer, filtl); \
+    } \
+    if (w == 4) \
+        filtl = filth; /* discard pixels 4-7 */ \
+    dstv = vec_packs(filth, filtl); \
+    dstv = vec_sra(dstv, c7)
+
+static av_always_inline
+void put_vp8_epel_h_altivec_core(uint8_t *dst, ptrdiff_t dst_stride,
+                                 const uint8_t *src, ptrdiff_t src_stride,
+                                 int h, int mx, int w, int is6tap)
+{
+    LOAD_H_SUBPEL_FILTER(mx-1);
+#if HAVE_BIGENDIAN == 1
+    vec_u8 align_vec0, align_vec8, permh0, permh8;
+    vec_u8 perm_6tap0, perm_6tap8, perml0, perml8;
+    vec_u8 b;
+#endif
+    vec_u8 filt, a, pixh, pixl, outer;
+    vec_s16 f16h, f16l;
+    vec_s32 filth, filtl;
+
+    vec_u8 perm_inner6 = { 1,2,3,4, 2,3,4,5, 3,4,5,6, 4,5,6,7 };
+    vec_u8 perm_inner4 = { 0,1,2,3, 1,2,3,4, 2,3,4,5, 3,4,5,6 };
+    vec_u8 perm_inner  = is6tap ? perm_inner6 : perm_inner4;
+    vec_u8 perm_outer = { 4,9, 0,5, 5,10, 1,6, 6,11, 2,7, 7,12, 3,8 };
+    vec_s32 c64 = vec_sl(vec_splat_s32(1), vec_splat_u32(6));
+    vec_u16 c7  = vec_splat_u16(7);
+
+#if HAVE_BIGENDIAN == 1
+    align_vec0 = vec_lvsl( -is6tap-1, src);
+    align_vec8 = vec_lvsl(8-is6tap-1, src);
+
+    permh0     = vec_perm(align_vec0, align_vec0, perm_inner);
+    permh8     = vec_perm(align_vec8, align_vec8, perm_inner);
+    perm_inner = vec_add(perm_inner, vec_splat_u8(4));
+    perml0     = vec_perm(align_vec0, align_vec0, perm_inner);
+    perml8     = vec_perm(align_vec8, align_vec8, perm_inner);
+    perm_6tap0 = vec_perm(align_vec0, align_vec0, perm_outer);
+    perm_6tap8 = vec_perm(align_vec8, align_vec8, perm_outer);
+#endif
+
+    while (h --> 0) {
+        FILTER_H(f16h, 0);
+
+        if (w == 16) {
+            FILTER_H(f16l, 8);
+            filt = vec_packsu(f16h, f16l);
+            vec_st(filt, 0, dst);
+        } else {
+            filt = vec_packsu(f16h, f16h);
+            vec_ste((vec_u32)filt, 0, (uint32_t*)dst);
+            if (w == 8)
+                vec_ste((vec_u32)filt, 4, (uint32_t*)dst);
+        }
+        src += src_stride;
+        dst += dst_stride;
+    }
+}
+
+// v subpel filter does a simple vertical multiply + add
+static const vec_u8 v_subpel_filters[7] =
+{
+    { 0,   6, 123,  12,   1,   0 },
+    { 2,  11, 108,  36,   8,   1 },
+    { 0,   9,  93,  50,   6,   0 },
+    { 3,  16,  77,  77,  16,   3 },
+    { 0,   6,  50,  93,   9,   0 },
+    { 1,   8,  36, 108,  11,   2 },
+    { 0,   1,  12, 123,   6,   0 },
+};
+
+#define LOAD_V_SUBPEL_FILTER(i) \
+    vec_u8 subpel_filter = v_subpel_filters[i]; \
+    vec_u8 f0 = vec_splat(subpel_filter, 0); \
+    vec_u8 f1 = vec_splat(subpel_filter, 1); \
+    vec_u8 f2 = vec_splat(subpel_filter, 2); \
+    vec_u8 f3 = vec_splat(subpel_filter, 3); \
+    vec_u8 f4 = vec_splat(subpel_filter, 4); \
+    vec_u8 f5 = vec_splat(subpel_filter, 5)
+
+#define FILTER_V(dstv, vec_mul) \
+    s1f = (vec_s16)vec_mul(s1, f1); \
+    s2f = (vec_s16)vec_mul(s2, f2); \
+    s3f = (vec_s16)vec_mul(s3, f3); \
+    s4f = (vec_s16)vec_mul(s4, f4); \
+    s2f = vec_subs(s2f, s1f); \
+    s3f = vec_subs(s3f, s4f); \
+    if (is6tap) { \
+        s0f = (vec_s16)vec_mul(s0, f0); \
+        s5f = (vec_s16)vec_mul(s5, f5); \
+        s2f = vec_adds(s2f, s0f); \
+        s3f = vec_adds(s3f, s5f); \
+    } \
+    dstv = vec_adds(s2f, s3f); \
+    dstv = vec_adds(dstv, c64); \
+    dstv = vec_sra(dstv, c7)
+
+#if HAVE_BIGENDIAN == 1
+#define LOAD_HL(off, s, perm) load_with_perm_vec(off, s, perm)
+#else
+#define LOAD_HL(off, s, perm) vec_mergeh(vec_vsx_ld(off,s), vec_vsx_ld(off+8,s))
+#endif
+
+static av_always_inline
+void put_vp8_epel_v_altivec_core(uint8_t *dst, ptrdiff_t dst_stride,
+                                 const uint8_t *src, ptrdiff_t src_stride,
+                                 int h, int my, int w, int is6tap)
+{
+    LOAD_V_SUBPEL_FILTER(my-1);
+    vec_u8 s0, s1, s2, s3, s4, s5, filt, align_vech, perm_vec, align_vecl;
+    vec_s16 s0f, s1f, s2f, s3f, s4f, s5f, f16h, f16l;
+    vec_s16 c64 = vec_sl(vec_splat_s16(1), vec_splat_u16(6));
+    vec_u16 c7  = vec_splat_u16(7);
+
+#if HAVE_BIGENDIAN == 1
+    // we want pixels 0-7 to be in the even positions and 8-15 in the odd,
+    // so combine this permute with the alignment permute vector
+    align_vech = vec_lvsl(0, src);
+    align_vecl = vec_sld(align_vech, align_vech, 8);
+    if (w ==16)
+        perm_vec = vec_mergeh(align_vech, align_vecl);
+    else
+        perm_vec = vec_mergeh(align_vech, align_vech);
+#endif
+
+    if (is6tap)
+        s0 = LOAD_HL(-2*src_stride, src, perm_vec);
+    s1 = LOAD_HL(-1*src_stride, src, perm_vec);
+    s2 = LOAD_HL( 0*src_stride, src, perm_vec);
+    s3 = LOAD_HL( 1*src_stride, src, perm_vec);
+    if (is6tap)
+        s4 = LOAD_HL( 2*src_stride, src, perm_vec);
+
+    src += (2+is6tap)*src_stride;
+
+    while (h --> 0) {
+        if (is6tap)
+            s5 = LOAD_HL(0, src, perm_vec);
+        else
+            s4 = LOAD_HL(0, src, perm_vec);
+
+        FILTER_V(f16h, vec_mule);
+
+        if (w == 16) {
+            FILTER_V(f16l, vec_mulo);
+            filt = vec_packsu(f16h, f16l);
+            vec_st(filt, 0, dst);
+        } else {
+            filt = vec_packsu(f16h, f16h);
+            if (w == 4)
+                filt = (vec_u8)vec_splat((vec_u32)filt, 0);
+            else
+                vec_ste((vec_u32)filt, 4, (uint32_t*)dst);
+            vec_ste((vec_u32)filt, 0, (uint32_t*)dst);
+        }
+
+        if (is6tap)
+            s0 = s1;
+        s1 = s2;
+        s2 = s3;
+        s3 = s4;
+        if (is6tap)
+            s4 = s5;
+
+        dst += dst_stride;
+        src += src_stride;
+    }
+}
+
+#define EPEL_FUNCS(WIDTH, TAPS) \
+static av_noinline \
+void put_vp8_epel ## WIDTH ## _h ## TAPS ## _altivec(uint8_t *dst, ptrdiff_t dst_stride, const uint8_t *src, ptrdiff_t src_stride, int h, int mx, int my) \
+{ \
+    put_vp8_epel_h_altivec_core(dst, dst_stride, src, src_stride, h, mx, WIDTH, TAPS == 6); \
+} \
+\
+static av_noinline \
+void put_vp8_epel ## WIDTH ## _v ## TAPS ## _altivec(uint8_t *dst, ptrdiff_t dst_stride, const uint8_t *src, ptrdiff_t src_stride, int h, int mx, int my) \
+{ \
+    put_vp8_epel_v_altivec_core(dst, dst_stride, src, src_stride, h, my, WIDTH, TAPS == 6); \
+}
+
+#define EPEL_HV(WIDTH, HTAPS, VTAPS) \
+static void put_vp8_epel ## WIDTH ## _h ## HTAPS ## v ## VTAPS ## _altivec(uint8_t *dst, ptrdiff_t dstride, const uint8_t *src, ptrdiff_t sstride, int h, int mx, int my) \
+{ \
+    DECLARE_ALIGNED(16, uint8_t, tmp)[(2*WIDTH+5)*16]; \
+    if (VTAPS == 6) { \
+        put_vp8_epel ## WIDTH ## _h ## HTAPS ## _altivec(tmp, 16,      src-2*sstride, sstride, h+5, mx, my); \
+        put_vp8_epel ## WIDTH ## _v ## VTAPS ## _altivec(dst, dstride, tmp+2*16,      16,      h,   mx, my); \
+    } else { \
+        put_vp8_epel ## WIDTH ## _h ## HTAPS ## _altivec(tmp, 16,      src-sstride, sstride, h+4, mx, my); \
+        put_vp8_epel ## WIDTH ## _v ## VTAPS ## _altivec(dst, dstride, tmp+16,      16,      h,   mx, my); \
+    } \
+}
+
+EPEL_FUNCS(16,6)
+EPEL_FUNCS(8, 6)
+EPEL_FUNCS(8, 4)
+EPEL_FUNCS(4, 6)
+EPEL_FUNCS(4, 4)
+
+EPEL_HV(16, 6,6)
+EPEL_HV(8,  6,6)
+EPEL_HV(8,  4,6)
+EPEL_HV(8,  6,4)
+EPEL_HV(8,  4,4)
+EPEL_HV(4,  6,6)
+EPEL_HV(4,  4,6)
+EPEL_HV(4,  6,4)
+EPEL_HV(4,  4,4)
+
+static void put_vp8_pixels16_altivec(uint8_t *dst, ptrdiff_t dstride, const uint8_t *src, ptrdiff_t sstride, int h, int mx, int my)
+{
+    register vector unsigned char perm;
+    int i;
+    register ptrdiff_t dstride2 = dstride << 1, sstride2 = sstride << 1;
+    register ptrdiff_t dstride3 = dstride2 + dstride, sstride3 = sstride + sstride2;
+    register ptrdiff_t dstride4 = dstride << 2, sstride4 = sstride << 2;
+
+#if HAVE_BIGENDIAN == 1
+    perm = vec_lvsl(0, src);
+#endif
+// hand-unrolling the loop by 4 gains about 15%
+// mininum execution time goes from 74 to 60 cycles
+// it's faster than -funroll-loops, but using
+// -funroll-loops w/ this is bad - 74 cycles again.
+// all this is on a 7450, tuning for the 7450
+    for (i = 0; i < h; i += 4) {
+        vec_st(load_with_perm_vec(0, src, perm), 0, dst);
+        vec_st(load_with_perm_vec(sstride, src, perm), dstride, dst);
+        vec_st(load_with_perm_vec(sstride2, src, perm), dstride2, dst);
+        vec_st(load_with_perm_vec(sstride3, src, perm), dstride3, dst);
+        src += sstride4;
+        dst += dstride4;
+    }
+}
+
+#endif /* HAVE_ALTIVEC */
+
+
+av_cold void ff_vp78dsp_init_ppc(VP8DSPContext *c)
+{
+#if HAVE_ALTIVEC == 1
+    if (!PPC_ALTIVEC(av_get_cpu_flags()))
+        return;
+
+    c->put_vp8_epel_pixels_tab[0][0][0] = put_vp8_pixels16_altivec;
+    c->put_vp8_epel_pixels_tab[0][0][2] = put_vp8_epel16_h6_altivec;
+    c->put_vp8_epel_pixels_tab[0][2][0] = put_vp8_epel16_v6_altivec;
+    c->put_vp8_epel_pixels_tab[0][2][2] = put_vp8_epel16_h6v6_altivec;
+
+    c->put_vp8_epel_pixels_tab[1][0][2] = put_vp8_epel8_h6_altivec;
+    c->put_vp8_epel_pixels_tab[1][2][0] = put_vp8_epel8_v6_altivec;
+    c->put_vp8_epel_pixels_tab[1][0][1] = put_vp8_epel8_h4_altivec;
+    c->put_vp8_epel_pixels_tab[1][1][0] = put_vp8_epel8_v4_altivec;
+
+    c->put_vp8_epel_pixels_tab[1][2][2] = put_vp8_epel8_h6v6_altivec;
+    c->put_vp8_epel_pixels_tab[1][1][1] = put_vp8_epel8_h4v4_altivec;
+    c->put_vp8_epel_pixels_tab[1][1][2] = put_vp8_epel8_h6v4_altivec;
+    c->put_vp8_epel_pixels_tab[1][2][1] = put_vp8_epel8_h4v6_altivec;
+
+    c->put_vp8_epel_pixels_tab[2][0][2] = put_vp8_epel4_h6_altivec;
+    c->put_vp8_epel_pixels_tab[2][2][0] = put_vp8_epel4_v6_altivec;
+    c->put_vp8_epel_pixels_tab[2][0][1] = put_vp8_epel4_h4_altivec;
+    c->put_vp8_epel_pixels_tab[2][1][0] = put_vp8_epel4_v4_altivec;
+
+    c->put_vp8_epel_pixels_tab[2][2][2] = put_vp8_epel4_h6v6_altivec;
+    c->put_vp8_epel_pixels_tab[2][1][1] = put_vp8_epel4_h4v4_altivec;
+    c->put_vp8_epel_pixels_tab[2][1][2] = put_vp8_epel4_h6v4_altivec;
+    c->put_vp8_epel_pixels_tab[2][2][1] = put_vp8_epel4_h4v6_altivec;
+#endif /* HAVE_ALTIVEC */
+}
diff --git a/media/ffvpx/libavutil/moz.build b/media/ffvpx/libavutil/moz.build
index 525e154c5b..e3c393fc2d 100644
--- a/media/ffvpx/libavutil/moz.build
+++ b/media/ffvpx/libavutil/moz.build
@@ -13,6 +13,8 @@ if CONFIG['FFVPX_ASFLAGS']:
 
 if CONFIG['CPU_ARCH'] == 'aarch64':
     DIRS += ['aarch64']
+elif CONFIG['CPU_ARCH'].startswith('ppc'):
+    DIRS += ['ppc']
 
 SharedLibrary('mozavutil')
 SOURCES += [
diff --git a/media/ffvpx/libavutil/ppc/cpu.c b/media/ffvpx/libavutil/ppc/cpu.c
new file mode 100644
index 0000000000..286a24428b
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/cpu.c
@@ -0,0 +1,165 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "config.h"
+
+#ifdef __APPLE__
+#include <sys/sysctl.h>
+#elif defined(__linux__)
+#include <asm/cputable.h>
+#include <linux/auxvec.h>
+#include <fcntl.h>
+#if HAVE_UNISTD_H == 1
+#include <unistd.h>
+#endif
+#elif defined(__NetBSD__) || defined(__OpenBSD__)
+#include <sys/types.h>
+#include <sys/sysctl.h>
+#include <machine/cpu.h>
+#elif defined(__AMIGAOS4__)
+#include <exec/exec.h>
+#include <interfaces/exec.h>
+#include <proto/exec.h>
+#endif /* __APPLE__ */
+
+#include "libavutil/avassert.h"
+#include "libavutil/cpu.h"
+#include "libavutil/cpu_internal.h"
+
+/**
+ * This function MAY rely on signal() or fork() in order to make sure AltiVec
+ * is present.
+ */
+int ff_get_cpu_flags_ppc(void)
+{
+#if HAVE_ALTIVEC == 1
+#ifdef __AMIGAOS4__
+    ULONG result = 0;
+    extern struct ExecIFace *IExec;
+
+    IExec->GetCPUInfoTags(GCIT_VectorUnit, &result, TAG_DONE);
+    if (result == VECTORTYPE_ALTIVEC)
+        return AV_CPU_FLAG_ALTIVEC;
+    return 0;
+#elif defined(__APPLE__) || defined(__NetBSD__) || defined(__OpenBSD__)
+#if defined(__NetBSD__) || defined(__OpenBSD__)
+    int sels[2] = {CTL_MACHDEP, CPU_ALTIVEC};
+#else
+    int sels[2] = {CTL_HW, HW_VECTORUNIT};
+#endif
+    int has_vu = 0;
+    size_t len = sizeof(has_vu);
+    int err;
+
+    err = sysctl(sels, 2, &has_vu, &len, NULL, 0);
+
+    if (err == 0)
+        return has_vu ? AV_CPU_FLAG_ALTIVEC : 0;
+    return 0;
+#elif defined(__linux__)
+    // The linux kernel could have the altivec support disabled
+    // even if the cpu has it.
+    int i, ret = 0;
+    int fd = open("/proc/self/auxv", O_RDONLY);
+    unsigned long buf[64] = { 0 };
+    ssize_t count;
+
+    if (fd < 0)
+        return 0;
+
+    while ((count = read(fd, buf, sizeof(buf))) > 0) {
+        for (i = 0; i < count / sizeof(*buf); i += 2) {
+            if (buf[i] == AT_NULL)
+                goto out;
+            if (buf[i] == AT_HWCAP) {
+                if (buf[i + 1] & PPC_FEATURE_HAS_ALTIVEC)
+                    ret = AV_CPU_FLAG_ALTIVEC;
+#ifdef PPC_FEATURE_HAS_VSX
+                if (buf[i + 1] & PPC_FEATURE_HAS_VSX)
+                    ret |= AV_CPU_FLAG_VSX;
+#endif
+                if (ret & AV_CPU_FLAG_VSX)
+                    av_assert0(ret & AV_CPU_FLAG_ALTIVEC);
+            }
+#ifdef AT_HWCAP2 /* not introduced until glibc 2.18 */
+            else if (buf[i] == AT_HWCAP2) {
+#ifdef PPC_FEATURE2_ARCH_2_07
+                if (buf[i + 1] & PPC_FEATURE2_ARCH_2_07)
+                    ret |= AV_CPU_FLAG_POWER8;
+#endif
+            }
+#endif /* AT_HWCAP2 */
+        }
+    }
+
+out:
+    close(fd);
+    return ret;
+#elif CONFIG_RUNTIME_CPUDETECT && defined(__linux__)
+#define PVR_G4_7400  0x000C
+#define PVR_G5_970   0x0039
+#define PVR_G5_970FX 0x003C
+#define PVR_G5_970MP 0x0044
+#define PVR_G5_970GX 0x0045
+#define PVR_POWER6   0x003E
+#define PVR_POWER7   0x003F
+#define PVR_POWER8   0x004B
+#define PVR_CELL_PPU 0x0070
+    int ret = 0;
+    int proc_ver;
+    // Support of mfspr PVR emulation added in Linux 2.6.17.
+    __asm__ volatile("mfspr %0, 287" : "=r" (proc_ver));
+    proc_ver >>= 16;
+    if (proc_ver  & 0x8000 ||
+        proc_ver == PVR_G4_7400  ||
+        proc_ver == PVR_G5_970   ||
+        proc_ver == PVR_G5_970FX ||
+        proc_ver == PVR_G5_970MP ||
+        proc_ver == PVR_G5_970GX ||
+        proc_ver == PVR_POWER6   ||
+        proc_ver == PVR_POWER7   ||
+        proc_ver == PVR_POWER8   ||
+        proc_ver == PVR_CELL_PPU)
+        ret = AV_CPU_FLAG_ALTIVEC;
+    if (proc_ver == PVR_POWER7 ||
+        proc_ver == PVR_POWER8)
+        ret |= AV_CPU_FLAG_VSX;
+    if (proc_ver == PVR_POWER8)
+        ret |= AV_CPU_FLAG_POWER8;
+
+    return ret;
+#else
+    // Since we were compiled for AltiVec, just assume we have it
+    // until someone comes up with a proper way (not involving signal hacks).
+    return AV_CPU_FLAG_ALTIVEC;
+#endif /* __AMIGAOS4__ */
+#endif /* HAVE_ALTIVEC */
+    return 0;
+}
+
+size_t ff_get_cpu_max_align_ppc(void)
+{
+    int flags = av_get_cpu_flags();
+
+    if (flags & (AV_CPU_FLAG_ALTIVEC   |
+                 AV_CPU_FLAG_VSX       |
+                 AV_CPU_FLAG_POWER8))
+        return 16;
+
+    return 8;
+}
diff --git a/media/ffvpx/libavutil/ppc/cpu.h b/media/ffvpx/libavutil/ppc/cpu.h
new file mode 100644
index 0000000000..36973a54ea
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/cpu.h
@@ -0,0 +1,29 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVUTIL_PPC_CPU_H
+#define AVUTIL_PPC_CPU_H
+
+#include "libavutil/cpu.h"
+#include "libavutil/cpu_internal.h"
+
+#define PPC_ALTIVEC(flags) CPUEXT(flags, ALTIVEC)
+#define PPC_VSX(flags) CPUEXT(flags, VSX)
+#define PPC_POWER8(flags) CPUEXT(flags, POWER8)
+
+#endif /* AVUTIL_PPC_CPU_H */
diff --git a/media/ffvpx/libavutil/ppc/float_dsp_altivec.c b/media/ffvpx/libavutil/ppc/float_dsp_altivec.c
new file mode 100644
index 0000000000..0eaee9d5ca
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/float_dsp_altivec.c
@@ -0,0 +1,124 @@
+/*
+ * Copyright (c) 2006 Luca Barbato <lu_zero@gentoo.org>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "util_altivec.h"
+#include "float_dsp_altivec.h"
+
+#if HAVE_ALTIVEC == 1
+void ff_vector_fmul_altivec(float *dst, const float *src0, const float *src1,
+                            int len)
+{
+    int i;
+    vec_f d0, d1, s, zero = (vec_f)vec_splat_u32(0);
+    for (i = 0; i < len - 7; i += 8) {
+        d0 = vec_ld( 0, src0 + i);
+        s  = vec_ld( 0, src1 + i);
+        d1 = vec_ld(16, src0 + i);
+        d0 = vec_madd(d0, s, zero);
+        d1 = vec_madd(d1, vec_ld(16, src1 + i), zero);
+        vec_st(d0,  0, dst + i);
+        vec_st(d1, 16, dst + i);
+    }
+}
+
+void ff_vector_fmul_window_altivec(float *dst, const float *src0,
+                                   const float *src1, const float *win, int len)
+{
+    vec_f zero, t0, t1, s0, s1, wi, wj;
+    const vec_u8 reverse = vcprm(3, 2, 1, 0);
+    int i, j;
+
+    dst  += len;
+    win  += len;
+    src0 += len;
+
+    zero = (vec_f)vec_splat_u32(0);
+
+    for (i = -len * 4, j = len * 4 - 16; i < 0; i += 16, j -= 16) {
+        s0 = vec_ld(i, src0);
+        s1 = vec_ld(j, src1);
+        wi = vec_ld(i, win);
+        wj = vec_ld(j, win);
+
+        s1 = vec_perm(s1, s1, reverse);
+        wj = vec_perm(wj, wj, reverse);
+
+        t0 = vec_madd(s0, wj, zero);
+        t0 = vec_nmsub(s1, wi, t0);
+        t1 = vec_madd(s0, wi, zero);
+        t1 = vec_madd(s1, wj, t1);
+        t1 = vec_perm(t1, t1, reverse);
+
+        vec_st(t0, i, dst);
+        vec_st(t1, j, dst);
+    }
+}
+
+void ff_vector_fmul_add_altivec(float *dst, const float *src0,
+                                const float *src1, const float *src2,
+                                int len)
+{
+    int i;
+    vec_f d, ss0, ss1, ss2, t0, t1, edges;
+
+    for (i = 0; i < len - 3; i += 4) {
+        t0 = vec_ld(0, dst + i);
+        t1 = vec_ld(15, dst + i);
+        ss0 = vec_ld(0, src0 + i);
+        ss1 = vec_ld(0, src1 + i);
+        ss2 = vec_ld(0, src2 + i);
+        edges = vec_perm(t1, t0, vcprm(0, 1, 2, 3));
+        d = vec_madd(ss0, ss1, ss2);
+        t1 = vec_perm(d, edges, vcprm(s0,s1,s2,s3));
+        t0 = vec_perm(edges, d, vcprm(s0,s1,s2,s3));
+        vec_st(t1, 15, dst + i);
+        vec_st(t0, 0, dst + i);
+    }
+}
+
+void ff_vector_fmul_reverse_altivec(float *dst, const float *src0,
+                                    const float *src1, int len)
+{
+    int i;
+    vec_f d, s0, s1, h0, l0, s2, s3;
+    vec_f zero = (vec_f)vec_splat_u32(0);
+
+    src1 += len-4;
+    for(i = 0; i < len - 7; i += 8) {
+        s1 = vec_ld(0, src1 - i);              // [a,b,c,d]
+        s0 = vec_ld(0, src0 + i);
+        l0 = vec_mergel(s1, s1);               // [c,c,d,d]
+        s3 = vec_ld(-16, src1 - i);
+        h0 = vec_mergeh(s1, s1);               // [a,a,b,b]
+        s2 = vec_ld(16, src0 + i);
+        s1 = vec_mergeh(vec_mergel(l0, h0),    // [d,b,d,b]
+                        vec_mergeh(l0, h0));   // [c,a,c,a]
+        // [d,c,b,a]
+        l0 = vec_mergel(s3, s3);
+        d = vec_madd(s0, s1, zero);
+        h0 = vec_mergeh(s3, s3);
+        vec_st(d, 0, dst + i);
+        s3 = vec_mergeh(vec_mergel(l0, h0),
+                        vec_mergeh(l0, h0));
+        d = vec_madd(s2, s3, zero);
+        vec_st(d, 16, dst + i);
+    }
+}
+#endif
diff --git a/media/ffvpx/libavutil/ppc/float_dsp_altivec.h b/media/ffvpx/libavutil/ppc/float_dsp_altivec.h
new file mode 100644
index 0000000000..e1d530afa5
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/float_dsp_altivec.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (c) 2006 Luca Barbato <lu_zero@gentoo.org>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVUTIL_PPC_FLOAT_DSP_ALTIVEC_H
+#define AVUTIL_PPC_FLOAT_DSP_ALTIVEC_H
+
+void ff_vector_fmul_altivec(float *dst, const float *src0,
+                            const float *src1, int len);
+
+void ff_vector_fmul_window_altivec(float *dst, const float *src0,
+                                   const float *src1, const float *win,
+                                   int len);
+
+void ff_vector_fmul_add_altivec(float *dst, const float *src0,
+                                const float *src1, const float *src2,
+                                int len);
+
+void ff_vector_fmul_reverse_altivec(float *dst, const float *src0,
+                                    const float *src1, int len);
+
+#endif /* AVUTIL_PPC_FLOAT_DSP_ALTIVEC_H */
diff --git a/media/ffvpx/libavutil/ppc/float_dsp_init.c b/media/ffvpx/libavutil/ppc/float_dsp_init.c
new file mode 100644
index 0000000000..1d490bd94c
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/float_dsp_init.c
@@ -0,0 +1,52 @@
+/*
+ * Copyright (c) 2006 Luca Barbato <lu_zero@gentoo.org>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "config.h"
+#include "libavutil/attributes.h"
+#include "libavutil/cpu.h"
+#include "libavutil/float_dsp.h"
+#include "libavutil/ppc/cpu.h"
+#include "float_dsp_altivec.h"
+#include "float_dsp_vsx.h"
+
+av_cold void ff_float_dsp_init_ppc(AVFloatDSPContext *fdsp, int bit_exact)
+{
+    if (PPC_ALTIVEC(av_get_cpu_flags())) {
+        fdsp->vector_fmul = ff_vector_fmul_altivec;
+        fdsp->vector_fmul_add = ff_vector_fmul_add_altivec;
+        fdsp->vector_fmul_reverse = ff_vector_fmul_reverse_altivec;
+
+        if (!bit_exact) {
+            fdsp->vector_fmul_window = ff_vector_fmul_window_altivec;
+        }
+    }
+
+    // The disabled function below are near identical to altivec and have
+    // been disabled to reduce code duplication
+    if (PPC_VSX(av_get_cpu_flags())) {
+//         fdsp->vector_fmul = ff_vector_fmul_vsx;
+        fdsp->vector_fmul_add = ff_vector_fmul_add_vsx;
+//         fdsp->vector_fmul_reverse = ff_vector_fmul_reverse_vsx;
+
+//         if (!bit_exact) {
+//             fdsp->vector_fmul_window = ff_vector_fmul_window_vsx;
+//         }
+    }
+}
diff --git a/media/ffvpx/libavutil/ppc/float_dsp_vsx.c b/media/ffvpx/libavutil/ppc/float_dsp_vsx.c
new file mode 100644
index 0000000000..9b74180294
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/float_dsp_vsx.c
@@ -0,0 +1,119 @@
+/*
+ * Copyright (c) 2015 Luca Barbato <lu_zero@gentoo.org>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "util_altivec.h"
+#include "float_dsp_vsx.h"
+
+#if HAVE_DSP_VSX == 1
+void ff_vector_fmul_vsx(float *dst,
+                        const float *src0, const float *src1,
+                        int len)
+{
+    int i;
+    vec_f d0, d1, zero = (vec_f)vec_splat_u32(0);
+    for (i = 0; i < len - 7; i += 8) {
+        d0 = vec_vsx_ld( 0, src0 + i);
+        d1 = vec_vsx_ld(16, src0 + i);
+        d0 = vec_madd(d0, vec_vsx_ld( 0, src1 + i), zero);
+        d1 = vec_madd(d1, vec_vsx_ld(16, src1 + i), zero);
+        vec_vsx_st(d0,  0, dst + i);
+        vec_vsx_st(d1, 16, dst + i);
+    }
+}
+
+void ff_vector_fmul_window_vsx(float *dst, const float *src0,
+                               const float *src1, const float *win,
+                               int len)
+{
+    vec_f zero, t0, t1, s0, s1, wi, wj;
+    const vec_u8 reverse = vcprm(3, 2, 1, 0);
+    int i, j;
+
+    dst  += len;
+    win  += len;
+    src0 += len;
+
+    zero = (vec_f)vec_splat_u32(0);
+
+    for (i = -len * 4, j = len * 4 - 16; i < 0; i += 16, j -= 16) {
+        s0 = vec_vsx_ld(i, src0);
+        s1 = vec_vsx_ld(j, src1);
+        wi = vec_vsx_ld(i, win);
+        wj = vec_vsx_ld(j, win);
+
+        s1 = vec_perm(s1, s1, reverse);
+        wj = vec_perm(wj, wj, reverse);
+
+        t0 = vec_madd(s0, wj, zero);
+        t0 = vec_nmsub(s1, wi, t0);
+        t1 = vec_madd(s0, wi, zero);
+        t1 = vec_madd(s1, wj, t1);
+        t1 = vec_perm(t1, t1, reverse);
+
+        vec_vsx_st(t0, i, dst);
+        vec_vsx_st(t1, j, dst);
+    }
+}
+
+void ff_vector_fmul_add_vsx(float *dst, const float *src0,
+                            const float *src1, const float *src2,
+                            int len)
+{
+    int i;
+    vec_f d, s0, s1, s2;
+
+    for (i = 0; i < len - 3; i += 4) {
+        s0 = vec_vsx_ld(0, src0 + i);
+        s1 = vec_vsx_ld(0, src1 + i);
+        s2 = vec_vsx_ld(0, src2 + i);
+        d = vec_madd(s0, s1, s2);
+        vec_vsx_st(d, 0, dst + i);
+    }
+}
+
+void ff_vector_fmul_reverse_vsx(float *dst, const float *src0,
+                                const float *src1, int len)
+{
+    int i;
+    vec_f d, s0, s1, h0, l0, s2, s3;
+    vec_f zero = (vec_f)vec_splat_u32(0);
+
+    src1 += len - 4;
+    for (i = 0; i < len - 7; i += 8) {
+        s1 = vec_vsx_ld(0, src1 - i);              // [a,b,c,d]
+        s0 = vec_vsx_ld(0, src0 + i);
+        l0 = vec_mergel(s1, s1);               // [c,c,d,d]
+        s3 = vec_vsx_ld(-16, src1 - i);
+        h0 = vec_mergeh(s1, s1);               // [a,a,b,b]
+        s2 = vec_vsx_ld(16, src0 + i);
+        s1 = vec_mergeh(vec_mergel(l0, h0),    // [d,b,d,b]
+                        vec_mergeh(l0, h0));   // [c,a,c,a]
+        // [d,c,b,a]
+        l0 = vec_mergel(s3, s3);
+        d = vec_madd(s0, s1, zero);
+        h0 = vec_mergeh(s3, s3);
+        vec_vsx_st(d, 0, dst + i);
+        s3 = vec_mergeh(vec_mergel(l0, h0),
+                        vec_mergeh(l0, h0));
+        d = vec_madd(s2, s3, zero);
+        vec_vsx_st(d, 16, dst + i);
+    }
+}
+#endif
diff --git a/media/ffvpx/libavutil/ppc/float_dsp_vsx.h b/media/ffvpx/libavutil/ppc/float_dsp_vsx.h
new file mode 100644
index 0000000000..5d3cc5ede9
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/float_dsp_vsx.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (c) 2015 Luca Barbato <lu_zero@gentoo.org>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVUTIL_PPC_FLOAT_DSP_VSX_H
+#define AVUTIL_PPC_FLOAT_DSP_VSX_H
+
+void ff_vector_fmul_vsx(float *dst, const float *src0,
+                        const float *src1, int len);
+
+void ff_vector_fmul_window_vsx(float *dst, const float *src0,
+                               const float *src1, const float *win,
+                               int len);
+
+void ff_vector_fmul_add_vsx(float *dst, const float *src0,
+                            const float *src1, const float *src2,
+                            int len);
+
+void ff_vector_fmul_reverse_vsx(float *dst, const float *src0,
+                                const float *src1, int len);
+
+#endif /* AVUTIL_PPC_FLOAT_DSP_VSX_H */
diff --git a/media/ffvpx/libavutil/ppc/intreadwrite.h b/media/ffvpx/libavutil/ppc/intreadwrite.h
new file mode 100644
index 0000000000..68b6f57973
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/intreadwrite.h
@@ -0,0 +1,110 @@
+/*
+ * Copyright (c) 2008 Mans Rullgard <mans@mansr.com>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVUTIL_PPC_INTREADWRITE_H
+#define AVUTIL_PPC_INTREADWRITE_H
+
+#include <stdint.h>
+#include "config.h"
+
+#if HAVE_XFORM_ASM == 1
+
+#if HAVE_BIGENDIAN == 1
+#define AV_RL16 av_read_bswap16
+#define AV_WL16 av_write_bswap16
+#define AV_RL32 av_read_bswap32
+#define AV_WL32 av_write_bswap32
+#define AV_RL64 av_read_bswap64
+#define AV_WL64 av_write_bswap64
+
+#else
+#define AV_RB16 av_read_bswap16
+#define AV_WB16 av_write_bswap16
+#define AV_RB32 av_read_bswap32
+#define AV_WB32 av_write_bswap32
+#define AV_RB64 av_read_bswap64
+#define AV_WB64 av_write_bswap64
+
+#endif
+
+static av_always_inline uint16_t av_read_bswap16(const void *p)
+{
+    uint16_t v;
+    __asm__ ("lhbrx   %0, %y1" : "=r"(v) : "Z"(*(const uint16_t*)p));
+    return v;
+}
+
+static av_always_inline void av_write_bswap16(void *p, uint16_t v)
+{
+    __asm__ ("sthbrx  %1, %y0" : "=Z"(*(uint16_t*)p) : "r"(v));
+}
+
+static av_always_inline uint32_t av_read_bswap32(const void *p)
+{
+    uint32_t v;
+    __asm__ ("lwbrx   %0, %y1" : "=r"(v) : "Z"(*(const uint32_t*)p));
+    return v;
+}
+
+static av_always_inline void av_write_bswap32(void *p, uint32_t v)
+{
+    __asm__ ("stwbrx  %1, %y0" : "=Z"(*(uint32_t*)p) : "r"(v));
+}
+
+#if HAVE_LDBRX == 1
+
+static av_always_inline uint64_t av_read_bswap64(const void *p)
+{
+    uint64_t v;
+    __asm__ ("ldbrx   %0, %y1" : "=r"(v) : "Z"(*(const uint64_t*)p));
+    return v;
+}
+
+static av_always_inline void av_write_bswap64(void *p, uint64_t v)
+{
+    __asm__ ("stdbrx  %1, %y0" : "=Z"(*(uint64_t*)p) : "r"(v));
+}
+
+#else
+
+static av_always_inline uint64_t av_read_bswap64(const void *p)
+{
+    union { uint64_t v; uint32_t hl[2]; } v;
+    __asm__ ("lwbrx   %0, %y2  \n\t"
+             "lwbrx   %1, %y3  \n\t"
+             : "=&r"(v.hl[1]), "=r"(v.hl[0])
+             : "Z"(*(const uint32_t*)p), "Z"(*((const uint32_t*)p+1)));
+    return v.v;
+}
+
+static av_always_inline void av_write_bswap64(void *p, uint64_t v)
+{
+    union { uint64_t v; uint32_t hl[2]; } vv = { v };
+    __asm__ ("stwbrx  %2, %y0  \n\t"
+             "stwbrx  %3, %y1  \n\t"
+             : "=Z"(*(uint32_t*)p), "=Z"(*((uint32_t*)p+1))
+             : "r"(vv.hl[1]), "r"(vv.hl[0]));
+}
+
+#endif /* HAVE_LDBRX */
+
+#endif /* HAVE_XFORM_ASM */
+
+#endif /* AVUTIL_PPC_INTREADWRITE_H */
diff --git a/media/ffvpx/libavutil/ppc/moz.build b/media/ffvpx/libavutil/ppc/moz.build
new file mode 100644
index 0000000000..0871e93760
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/moz.build
@@ -0,0 +1,15 @@
+# -*- Mode: python; indent-tabs-mode: nil; tab-width: 40 -*-
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+
+SOURCES += [
+    'cpu.c',
+    'float_dsp_altivec.c',
+    'float_dsp_init.c',
+    'float_dsp_vsx.c',
+]
+
+FINAL_LIBRARY = 'mozavutil'
+
+include('/media/ffvpx/ffvpxcommon.mozbuild')
diff --git a/media/ffvpx/libavutil/ppc/timer.h b/media/ffvpx/libavutil/ppc/timer.h
new file mode 100644
index 0000000000..b28e624566
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/timer.h
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2005 Luca Barbato <lu_zero@gentoo.org>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVUTIL_PPC_TIMER_H
+#define AVUTIL_PPC_TIMER_H
+
+#include <stdint.h>
+
+#include "config.h"
+
+#define AV_READ_TIME read_time
+
+static inline uint64_t read_time(void)
+{
+    uint32_t tbu, tbl, temp;
+
+     /* from section 2.2.1 of the 32-bit PowerPC PEM */
+     __asm__ volatile(
+         "mftbu  %2\n"
+         "mftb   %0\n"
+         "mftbu  %1\n"
+         "cmpw   %2,%1\n"
+         "bne    $-0x10\n"
+     : "=r"(tbl), "=r"(tbu), "=r"(temp)
+     :
+     : "cc");
+
+     return (((uint64_t)tbu)<<32) | (uint64_t)tbl;
+}
+
+#endif /* AVUTIL_PPC_TIMER_H */
diff --git a/media/ffvpx/libavutil/ppc/util_altivec.h b/media/ffvpx/libavutil/ppc/util_altivec.h
new file mode 100644
index 0000000000..0ca937db30
--- /dev/null
+++ b/media/ffvpx/libavutil/ppc/util_altivec.h
@@ -0,0 +1,195 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * Contains misc utility macros and inline functions
+ */
+
+#ifndef AVUTIL_PPC_UTIL_ALTIVEC_H
+#define AVUTIL_PPC_UTIL_ALTIVEC_H
+
+#include <stdint.h>
+
+#include "config.h"
+
+/***********************************************************************
+ * Vector types
+ **********************************************************************/
+#define vec_u8  vector unsigned char
+#define vec_s8  vector signed char
+#define vec_u16 vector unsigned short
+#define vec_s16 vector signed short
+#define vec_u32 vector unsigned int
+#define vec_s32 vector signed int
+#define vec_f   vector float
+
+/***********************************************************************
+ * Null vector
+ **********************************************************************/
+#define LOAD_ZERO const vec_u8 zerov = vec_splat_u8( 0 )
+
+#define zero_u8v  (vec_u8)  zerov
+#define zero_s8v  (vec_s8)  zerov
+#define zero_u16v (vec_u16) zerov
+#define zero_s16v (vec_s16) zerov
+#define zero_u32v (vec_u32) zerov
+#define zero_s32v (vec_s32) zerov
+
+#if HAVE_ALTIVEC == 1
+#include <altivec.h>
+
+// used to build registers permutation vectors (vcprm)
+// the 's' are for words in the _s_econd vector
+#define WORD_0 0x00,0x01,0x02,0x03
+#define WORD_1 0x04,0x05,0x06,0x07
+#define WORD_2 0x08,0x09,0x0a,0x0b
+#define WORD_3 0x0c,0x0d,0x0e,0x0f
+#define WORD_s0 0x10,0x11,0x12,0x13
+#define WORD_s1 0x14,0x15,0x16,0x17
+#define WORD_s2 0x18,0x19,0x1a,0x1b
+#define WORD_s3 0x1c,0x1d,0x1e,0x1f
+#define vcprm(a,b,c,d) (const vec_u8){WORD_ ## a, WORD_ ## b, WORD_ ## c, WORD_ ## d}
+
+#define SWP_W2S0 0x02,0x03,0x00,0x01
+#define SWP_W2S1 0x06,0x07,0x04,0x05
+#define SWP_W2S2 0x0a,0x0b,0x08,0x09
+#define SWP_W2S3 0x0e,0x0f,0x0c,0x0d
+#define SWP_W2Ss0 0x12,0x13,0x10,0x11
+#define SWP_W2Ss1 0x16,0x17,0x14,0x15
+#define SWP_W2Ss2 0x1a,0x1b,0x18,0x19
+#define SWP_W2Ss3 0x1e,0x1f,0x1c,0x1d
+#define vcswapi2s(a,b,c,d) (const vector unsigned char){SWP_W2S ## a, SWP_W2S ## b, SWP_W2S ## c, SWP_W2S ## d}
+
+#define vcswapc() \
+  (const vector unsigned char){0x0f,0x0e,0x0d,0x0c,0x0b,0x0a,0x09,0x08,0x07,0x06,0x05,0x04,0x03,0x02,0x01,0x00}
+
+
+// Transpose 8x8 matrix of 16-bit elements (in-place)
+#define TRANSPOSE8(a,b,c,d,e,f,g,h) \
+do { \
+    vec_s16 A1, B1, C1, D1, E1, F1, G1, H1; \
+    vec_s16 A2, B2, C2, D2, E2, F2, G2, H2; \
+ \
+    A1 = vec_mergeh (a, e); \
+    B1 = vec_mergel (a, e); \
+    C1 = vec_mergeh (b, f); \
+    D1 = vec_mergel (b, f); \
+    E1 = vec_mergeh (c, g); \
+    F1 = vec_mergel (c, g); \
+    G1 = vec_mergeh (d, h); \
+    H1 = vec_mergel (d, h); \
+ \
+    A2 = vec_mergeh (A1, E1); \
+    B2 = vec_mergel (A1, E1); \
+    C2 = vec_mergeh (B1, F1); \
+    D2 = vec_mergel (B1, F1); \
+    E2 = vec_mergeh (C1, G1); \
+    F2 = vec_mergel (C1, G1); \
+    G2 = vec_mergeh (D1, H1); \
+    H2 = vec_mergel (D1, H1); \
+ \
+    a = vec_mergeh (A2, E2); \
+    b = vec_mergel (A2, E2); \
+    c = vec_mergeh (B2, F2); \
+    d = vec_mergel (B2, F2); \
+    e = vec_mergeh (C2, G2); \
+    f = vec_mergel (C2, G2); \
+    g = vec_mergeh (D2, H2); \
+    h = vec_mergel (D2, H2); \
+} while (0)
+
+
+#if HAVE_BIGENDIAN == 1
+#define VEC_LD(offset,b)                                   \
+    vec_perm(vec_ld(offset, b), vec_ld((offset)+15, b), vec_lvsl(offset, b))
+#else
+#define VEC_LD(offset,b)                                   \
+    vec_vsx_ld(offset, b)
+#endif
+
+/** @brief loads unaligned vector @a *src with offset @a offset
+    and returns it */
+#if HAVE_BIGENDIAN == 1
+static inline vec_u8 unaligned_load(int offset, const uint8_t *src)
+{
+    register vec_u8 first = vec_ld(offset, src);
+    register vec_u8 second = vec_ld(offset + 15, src);
+    register vec_u8 mask = vec_lvsl(offset, src);
+    return vec_perm(first, second, mask);
+}
+static inline vec_u8 load_with_perm_vec(int offset, const uint8_t *src, vec_u8 perm_vec)
+{
+    vec_u8 a = vec_ld(offset, src);
+    vec_u8 b = vec_ld(offset + 15, src);
+    return vec_perm(a, b, perm_vec);
+}
+#else
+#define unaligned_load(a,b) VEC_LD(a,b)
+#define load_with_perm_vec(a,b,c) VEC_LD(a,b)
+#endif
+
+
+/**
+ * loads vector known misalignment
+ * @param perm_vec the align permute vector to combine the two loads from lvsl
+ */
+
+#define vec_unaligned_load(b)  VEC_LD(0, b)
+
+#if HAVE_BIGENDIAN == 1
+#define VEC_MERGEH(a, b) vec_mergeh(a, b)
+#define VEC_MERGEL(a, b) vec_mergel(a, b)
+#else
+#define VEC_MERGEH(a, b) vec_mergeh(b, a)
+#define VEC_MERGEL(a, b) vec_mergel(b, a)
+#endif
+
+#if HAVE_BIGENDIAN == 1
+#define VEC_ST(a,b,c) vec_st(a,b,c)
+#else
+#define VEC_ST(a,b,c) vec_vsx_st(a,b,c)
+#endif
+
+#if HAVE_BIGENDIAN == 1
+#define VEC_SPLAT16(a,b) vec_splat((vec_s16)(a), b)
+#else
+#define VEC_SPLAT16(a,b) vec_splat((vec_s16)(vec_perm(a, a, vcswapi2s(0,1,2,3))), b)
+#endif
+
+#if HAVE_BIGENDIAN == 1
+#define VEC_SLD16(a,b,c) vec_sld(a, b, c)
+#else
+#define VEC_SLD16(a,b,c) vec_sld(b, a, c)
+#endif
+
+#endif /* HAVE_ALTIVEC */
+
+#if HAVE_VSX == 1
+#if HAVE_BIGENDIAN == 1
+#define vsx_ld_u8_s16(off, p)                               \
+    ((vec_s16)vec_mergeh((vec_u8)vec_splat_u8(0),           \
+                         (vec_u8)vec_vsx_ld((off), (p))))
+#else
+#define vsx_ld_u8_s16(off, p)                               \
+    ((vec_s16)vec_mergeh((vec_u8)vec_vsx_ld((off), (p)),    \
+                         (vec_u8)vec_splat_u8(0)))
+#endif /* HAVE_BIGENDIAN */
+#endif /* HAVE_VSX */
+
+#endif /* AVUTIL_PPC_UTIL_ALTIVEC_H */
